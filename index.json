[{"categories":null,"content":"《数据密集型应用系统设计》第8章-分布式系统的挑战","date":"2023-10-15","objectID":"/posts/the-trouble-with-distributed-systems/","tags":["数据密集型应用系统设计"],"title":"《数据密集型应用系统设计》第8章-分布式系统的挑战","uri":"/posts/the-trouble-with-distributed-systems/"},{"categories":null,"content":"网络不可靠 网络延迟 ​分组交换：以太网和IP都是基于此，最大限度利用带宽 ​电路交换：打电话，它的延迟可确定，但带宽利用率不高 网络拥塞 ​交换机的Head of Line Blocking问题 ​CPU繁忙 ​虚拟化环境下，VM切换造成暂停 ​TCP的拥塞控制，还没发出去，在本机就被拥塞控制了 ","date":"2023-10-15","objectID":"/posts/the-trouble-with-distributed-systems/:0:1","tags":["数据密集型应用系统设计"],"title":"《数据密集型应用系统设计》第8章-分布式系统的挑战","uri":"/posts/the-trouble-with-distributed-systems/"},{"categories":null,"content":"​时钟不可靠 ​墙上时钟 定义：​自1970.1.1以来的时间，以秒或毫秒为单位 问题： ​晶振不准确、偏移等问题 ​ntp同步问题 ​相差太大，拒绝同步 ​网络延迟问题 ​时间回跳问题 ​单调时钟 ​绝对值无意义，用来测量耗时（一般取值为开机运行时间） ​保证绝不回跳，因而得名 ​多路CPU，则相互之间的单调时钟可能存在偏差 ​事件发生顺序的测量 ​不能依赖于各个节点的墙上时钟 ​应该基于递增计数器的逻辑时钟 ","date":"2023-10-15","objectID":"/posts/the-trouble-with-distributed-systems/:0:2","tags":["数据密集型应用系统设计"],"title":"《数据密集型应用系统设计》第8章-分布式系统的挑战","uri":"/posts/the-trouble-with-distributed-systems/"},{"categories":null,"content":"拜占庭将军问题​ 拜占庭容错系统：恶意节点存在，但系统仍可继续正常运行 ​飞控系统、飞船等系统必须做到拜占庭容错 ​区块链：点对点，去中心化，就某项交易达成一致 ​大多数拜占庭容错系统要求不少于2/3的节点正常工作 ","date":"2023-10-15","objectID":"/posts/the-trouble-with-distributed-systems/:0:3","tags":["数据密集型应用系统设计"],"title":"《数据密集型应用系统设计》第8章-分布式系统的挑战","uri":"/posts/the-trouble-with-distributed-systems/"},{"categories":null,"content":"​Fencing令牌 ​为了防止进程暂停造成锁的误用，简单来说对锁加一个版本号，然后资源方只认可最新的版本号。 没加​Fencing令牌前： 加​Fencing令牌后： ","date":"2023-10-15","objectID":"/posts/the-trouble-with-distributed-systems/:0:4","tags":["数据密集型应用系统设计"],"title":"《数据密集型应用系统设计》第8章-分布式系统的挑战","uri":"/posts/the-trouble-with-distributed-systems/"},{"categories":null,"content":"一个排序问题","date":"2023-09-22","objectID":"/posts/sort-issue/","tags":["算法"],"title":"一个排序问题","uri":"/posts/sort-issue/"},{"categories":null,"content":"问题背景 去年开发的一个项目管理系统，我负责其中一部分后端逻辑。问题简要概述如下：有工作项(issue)，工作项之间有父子关系，父子关系最多有三层，即：祖父-\u003e父-\u003e子。工作项可以放置在不同的泳道(lane)里，且可以在泳道之间来回拖动，拖动之后，必须在泳道内和它的家族放置在一起。即在同一个泳道内，排序必须遵循如下规则： 如果有兄弟，则排在最后一个兄弟后面。 如果没有兄弟，但有父亲，则排在父亲后面。 如果既没有兄弟，也没有父亲，但有祖父，则排在祖父后面。 如果祖父也没有，则默认放在泳道的末尾。 如图所示： ","date":"2023-09-22","objectID":"/posts/sort-issue/:0:1","tags":["算法"],"title":"一个排序问题","uri":"/posts/sort-issue/"},{"categories":null,"content":"表结构 工作项 create table if not exists issue ( id varchar(64) not null comment 'UUID' primary key, title varchar(512) not null comment '标题', parent_id varchar(64) null comment '父工作项ID，Epic-\u003eFeature-\u003eStory-\u003eTask-\u003eSubtask，Story-\u003eBug', root_id varchar(64) null comment '根工作项ID，方便查询', type varchar(320) not null comment '工作项类型，支持Epic，Feature，Story，Task，Subtask，Bug六种', lane_id varchar(64) null comment '泳道ID', sort int(8) null comment '排序，工作项在泳道中的排序' ) comment '工作项'; 泳道 create table if not exists sprint_lane ( id varchar(64) not null comment 'UUID' primary key, name varchar(255) not null comment '名称', ) comment '迭代泳道'; ","date":"2023-09-22","objectID":"/posts/sort-issue/:0:2","tags":["算法"],"title":"一个排序问题","uri":"/posts/sort-issue/"},{"categories":null,"content":"解决方案 思路 泳道里的工作项实际上组成了一个多叉树，为了处理方便，引入一个虚拟祖先，这样便形成了四层的多叉树结构： 这样一来，排序问题就变成了一个多叉树的先序遍历，初始状态下的排序是这样进行的： 获取整个泳道内的工作项总数，假设总数为 $n_{1}$。 获取那些不在此泳道内的，但是和此泳道内的工作项有关联的工作项总数，比如子在此泳道内，父却在另一个泳道的。假设这个数字为 $n_{2}$。 按照总数$n_{1}+n_{2}$，先序遍历泳道内的这棵树，从高到低给工作项们排好序(即设置好sort值)。 遍历排序完后，把不在此泳道的父与祖issue剔除,再按照sort值重排下。 代码 排序初始化 /** * @param issuesInLane 待排序的issue列表,可能有有序的+无序的,也可能全是未排序的 * @return 排序后的issue列表 */ private List\u003cIssue\u003e sortIssues(List\u003cIssue\u003e issuesInLane) { Set\u003cString\u003e issueIdsInLane = issuesInLane.stream().map(Issue::getId).collect(Collectors.toSet()); if (CollUtil.isEmpty(issuesInLane)) { return issuesInLane; } /* 遍历issuesInLane，将不在此泳道的祖先也加入到issuesInLane中，便于levelOrder排序，排序完成后再作调整（看下面的removeIf） 需要递归一层一层往上找，直到找不到parentId为止，所以这里用了while循环，直到tempParentIds为空 因为光看parentId和rootId还是不够，层级远远不止三层，比如：epic-\u003efeature-\u003estory-\u003ebug epic和feature是不需要参与排序的，但是为了确定story和bug的排序，需要将epic和feature也加入到issuesInLane中 排序完成后再把它们移除，所以看到下面的while循环查询没有加.notIn(Issue::getType, IssueTypeEnum.ISSUE_TYPE_NO_NEED_SORT)这个条件 */ Set\u003cString\u003e tempParentIds = issuesInLane.stream().map(Issue::getParentId) .filter(parentId -\u003e StrUtil.isNotEmpty(parentId) \u0026\u0026 !issueIdsInLane.contains(parentId)) .collect(Collectors.toSet()); Set\u003cString\u003e issueIdsNotInLane = new HashSet\u003c\u003e(tempParentIds); while (CollUtil.isNotEmpty(tempParentIds)) { Set\u003cString\u003e parentIds = issueMapper.listIssue( new LambdaQueryWrapper\u003cIssue\u003e().in(Issue::getId, tempParentIds)).stream() .map(Issue::getParentId) .filter(parentId -\u003e StrUtil.isNotEmpty(parentId) \u0026\u0026 !issueIdsInLane.contains(parentId)) .collect(Collectors.toSet()); issueIdsNotInLane.addAll(parentIds); tempParentIds = parentIds; } if (CollUtil.isNotEmpty(issueIdsNotInLane)) { List\u003cIssue\u003e issuesNotInLane = issueMapper.listIssue(new LambdaQueryWrapper\u003cIssue\u003e().in(Issue::getId, issueIdsNotInLane)); issuesInLane.addAll(issuesNotInLane); } //按父分类,key为父id，value为子issue列表 Map\u003cOptional\u003cString\u003e, List\u003cIssue\u003e\u003e parentChildRel = issuesInLane.stream().filter(Objects::nonNull) //Optional.empty()表示一个虚拟的祖先,本来只有三层,为了后续树的遍历方便,增加一个虚拟祖先,变成了:孙-\u003e子-\u003e父-\u003e虚拟祖先 //因为groupingBy不允许null key //不允许null key，用Optional包装一下，以前这里用-1，后面保存数据库时还要重新设置为null，多了一次遍历的开销， .collect(Collectors.groupingBy(issue -\u003e Optional.ofNullable(issue.getParentId()))); Map\u003cOptional\u003cString\u003e, Issue\u003e issueMap = issuesInLane.stream().filter(Objects::nonNull) .collect(Collectors.toMap(issue -\u003e Optional.ofNullable(issue.getId()), Function.identity())); //注意这里的排序是同一级的排序,也就是兄弟间的排序,不涉及父子,父子关系的体现在下面的levelOrder方法中 for (List\u003cIssue\u003e siblings : parentChildRel.values()) { siblings.sort((issue1, issue2) -\u003e { if (issue1.getSort() == null || issue2.getSort() == null) { //只要有一个sort为空，则按照sequence排序 return issue2.getSequence().compareTo(issue1.getSequence()); } //两个都有序,按照原来的sort排序 return issue2.getSort().compareTo(issue1.getSort()); }); } //树的先序遍历 AtomicInteger counter = new AtomicInteger(issuesInLane.size()); List\u003cIssue\u003e result = new ArrayList\u003c\u003e(); //Optional.empty()表示虚拟的祖先 preOrder(Optional.empty(), result, parentChildRel, issueMap, counter); //遍历排序完后，把不在此泳道的父与祖issue剔除,再按照sort值重排下 result.removeIf(issue -\u003e issueIdsNotInLane.contains(issue.getId())); result.sort(Comparator.comparingInt(Issue::getSort).reversed()); AtomicInteger pureSort = new AtomicInteger(result.size()); result.forEach(issue -\u003e issue.setSort(pureSort.getAndDecrement())); return result; } //多叉树的先序遍历 // NULL // / | \\ // / | \\ // 2 3 4 // / \\ / | \\ // 5 6 7 8 9 // / / | \\ // 10 11 12 13 /** * preOrder的遍历顺序是NULL 2 5 10 6 11 12 13 3 4 7 8 9 * 排sort * * @param rootIssueId 树的根节点 * @param result 返回排好序的结果 * @param parentChildRel 父子关系，key为父id，value为儿子的集合 * @param issueMap 所有issue的map，key为issueId，value为issue * @param counter 计数器，用于给每个issue的sort赋值，从高到低递减 * @see \u003ca href=\"https://www.geeksforgeeks.org/iterative-preorder-traversal-of-a-n-ary-tree/\"\u003e多叉树的先序遍历\u003c/a\u003e */ private static void preOrder(Optional\u003cString\u003e rootIssueId, List\u003cIssue\u003e result, Map\u003cOptional\u003cString\u003e, List\u003cIssue\u003e\u003e parentChildRel, Map\u003cOptional\u003cString\u003e, Issue\u003e issueMap, AtomicInteger counter) { //虚拟祖先为Optional.empty(),不要加进去 if (rootIssueId.isPresent()) { Issue issue = issueMap.get(rootIssueId); issue.setSort(counter.getAndDecrement()); result.add(issue); } List\u003cIssue\u003e children = parentChildRel.get(rootIssueId); if (CollUtil.isEmpty(children)) { return; } for (Issue child : children) { preOrder(Optional.of(child.getId()), result, parentChildRel, issueMap, counter); } } 跨泳道拖动排序 @Data public class CrossLaneIssueSortVo extends BaseVo implements Serializable { private static final long serialVersionUID = 1L; @NotEmpty(message = \"项目ID\") private String projectId; @NotEmpty(message = \"工作项ID\") private String issueId; @NotEmpty(message = \"目标泳道ID\") private String targetLaneId; @NotEmpty(message = \"原泳道ID\") private String sourceLaneId; } /** * 跨泳道工作项排序 * 1.如果目标泳道内没有该issue的家族（家族指的是父、子、孙、兄），则放到泳道最下面 * 2.如果存在家族，则和家族放一起，家族的最后一个，即：有兄弟，放兄弟最后，有父亲，无兄弟，放父后面，无兄弟，无父亲，挂在祖父后面。 * 总而言之，要和家族聚集在一起 * @param vo */ public void sortIssueCrossLane(CrossLaneIssueSortVo vo) { //跨泳道拖动只会拖一个,不考虑父子关系 /* 将工作项拖动到 新泳道后，默认排在该”泳道“的最后一个。 无论该泳道有几个 状态，也无论拖进哪个状态框， 拖过去后默认直接排在该泳道的最后一个即可 （特殊情况：存在父子关系的工作项，子工作项始终排在父工作项下） 源泳道的工作项排序需要更新,大于此issue的全-1 调用此接口前,前端已经调用了updateIssue接口更新了issue状态,也就是说逻辑上,此时这个issue已经在新泳道了,只不过它的sort还没有更新 */ String targetLaneId = vo.getTargetLaneId(); SprintLane targetLane = sprintLaneMapper.selectOne(new LambdaQueryWrapper\u003cSprintLane\u003e().eq(SprintLane::getId, targetLaneId)); if (Objects.isNull(targetLane)) { ExceptionUtils.validParamException(targetLaneId, \"targetLaneId\", HttpStatus.NOT_FOUND, ProjectsExceptionCode.INVALID_SPRINT_LANE_NOTFOUND); } String sourceLaneId = vo.getSourceLaneId(); SprintLane sourceLane = sprintLaneMapper.selectOne(new LambdaQueryWrapper\u003cSprintLane\u003e().eq(SprintLane::getId, sourceLaneId)); if (Objects.isNull(sourceLane)) { ExceptionUtils.validParamException(sourceLaneId, \"sourceLaneId\", HttpStatus.NOT_FOUND, ProjectsExceptionCode.INVALID_SPRINT_LANE_NOTFOUND); } String issueId = vo.getIssueId(); Issue issue = issueService.getById(issueId); if (Objects.isNull(issue)) { ExceptionUtils.validParamException(issueId, \"issueId\", HttpStatus.NOT_FOUND, ProjectsExceptionCode.INVALID_ISSUE_NOT_FOUND); } String sprintId = issue.getSprintId(); String projectId = vo.getProjectId(); Set\u003cString\u003e stateIdsInTargetLane = Arrays.stream(targetLane.getStateIds().split(\",\")).collect(Collectors.toSet()); List\u003cIssue\u003e issuesInTargetLane = issueMapper.listIssue( new LambdaQueryWrapper\u003cIssue\u003e().in(Issue::getStateId, stateIdsInTargetLane) .in(Issue::getProjectId, projectId).notIn(Issue::getType, IssueTypeEnum.ISSUE_TYPE_NO_NEED_SORT) //eq是不为null的情况，isNotNull是为null的情况 .eq(StrUtil.isNotEmpty(sprintId), Issue::getSprintId, sprintId) .isNull(StrUtil.isEmpty(sprintId), Issue::getSprintId) //排除掉自己，因为调用此接口前,前端已经调用了updateIssue接口更新了issue状态,也就是说逻辑上,此时这个issue已经在targetLane了,只不过它的sort还没有更新 .ne(Issue::getId, issueId)); if (CollUtil.isEmpty(issuesInTargetLane)) { //1.如果目标泳道是空的,直接插入,sort值为1 //注意！！！updateIssueSortInSourceLane和issue.setSort顺序不能乱！！！因为updateIssueSortInSourceLane里要和原来的sort比较 updateIssueSortInSourceLane(projectId, sprintId, sourceLane, issue); issue.setSort(1); issueService.updateById(issue); return; } //2.如果目标泳道不是空的,则找到被拖工作项最终的归属 //先找同泳道内的父亲 String parentId = issue.getParentId(); Issue parentIssue = issueService.getOne(new LambdaQueryWrapper\u003cIssue\u003e().eq(Issue::getProjectId, projectId) .in(Issue::getStateId, stateIdsInTargetLane) .eq(StrUtil.isNotEmpty(sprintId), Issue::getSprintId, sprintId) .isNull(StrUtil.isEmpty(sprintId), Issue::getSprintId).eq(Issue::getId, parentId)); if (StringUtils.isBlank(parentId) || Objects.isNull(parentIssue)) { //根本没有父亲，或者父亲不在泳道内,则看是否在泳道内有子嗣 List\u003cIssue\u003e descendants = listFamily(issueId, sprintId, stateIdsInTargetLane, false); if (CollUtil.isEmpty(descendants)) { //在泳道内无依无靠（上无祖先，下无子嗣）则插入到最后,issues每个工作项的sort值都要+1 issuesInTargetLane.forEach(item -\u003e item.setSort(item.getSort() + 1)); updateIssueSortInSourceLane(projectId, sprintId, sourceLane, issue); issue.setSort(1); issuesInTargetLane.add(issue); if (CollUtil.isNotEmpty(issuesInTargetLane)) { issueService.updateBatchById(issuesInTargetLane); } return; } //有后代，放在后代前面，找出后代最大的sort值，大于sort值的issue，全都+1，然后插入到该sort值+1的位置 int maxSort = descendants.stream().mapToInt(Issue::getSort).max().orElse(1); issuesInTargetLane.stream().filter(item -\u003e item.getSort() \u003e maxSort) .forEach(item -\u003e item.setSort(item.getSort() + 1)); updateIssueSortInSourceLane(projectId, sprintId, sourceLane, issue); issue.setSort(maxSort + 1); issuesInTargetLane.add(issue); if (CollUtil.isNotEmpty(issuesInTargetLane)) { issueService.updateBatchById(issuesInTargetLane); } return; } //有同一泳道的父亲,挂在父亲后面 List\u003cIssue\u003e siblings = issueService.list(new LambdaQueryWrapper\u003cIssue\u003e().eq(Issue::getParentId, parentId) .in(Issue::getStateId, stateIdsInTargetLane) //排除掉自己 .ne(Issue::getId, issueId).in(Issue::getProjectId, projectId)); if (CollUtil.isEmpty(siblings)) { //没有兄弟,则跟在父亲后面,所有大于等于父亲的sort值都要+1,自己占据父亲原来的位置 updateIssueSortInSourceLane(projectId, sprintId, sourceLane, issue); insertAfter(issuesInTargetLane, issue, parentIssue.getSort()); return; } //有兄弟,则挂在最后一个兄弟后面,查询出最小sort值的兄弟,自己占据最小兄弟的位置,其他大于等于最小兄弟的sort值都要+1 Issue minSibling = siblings.stream().min(Comparator.comparing(Issue::getSort)).get(); //最后,把源泳道里大于等于源工作项的sort值都要-1 updateIssueSortInSourceLane(projectId, sprintId, sourceLane, issue); insertAfter(issuesInTargetLane, issue, minSibling.getSort()); } /** * 插入到targetSort的位置,大于等于targetSort的sort值都要+1 * * @param issuesInTargetLane 目标泳道的工作项集合 * @param issue 插入的工作项 * @param targetSort 插入的目标位置 */ private void insertAfter(List\u003cIssue\u003e issuesInTargetLane, Issue issue, Integer targetSort) { //插入到目标工作项后面 issue.setSort(targetSort); issuesInTargetLane.stream().filter(item -\u003e item.getSort() \u003e= targetSort) .forEach(item -\u003e item.setSort(item.getSort() + 1)); issuesInTargetLane.add(issue); if (CollUtil.isNotEmpty(issuesInTargetLane)) { issueService.updateBatchById(issuesInTargetLane); } } /** * 查询此issueId下的所有工作项和子工作项 * 不包括epic和feature，因为epic和feature不会在泳道中显示，不参与排序 * * @param issueId 祖先 * @param sprintId 迭代id * @param stateIds 泳道里的状态 * @param includeSelf 返回的结果是否包括祖先自己 * @return 家族 */ private List\u003cIssue\u003e listFamily(String issueId, String sprintId, Set\u003cString\u003e stateIds, boolean includeSelf) { List\u003cIssue\u003e result = new ArrayList\u003c\u003e(); if (StringUtils.isEmpty(issueId)) { return result; } if (includeSelf) { List\u003cIssue\u003e self = issueMapper.listIssue( new LambdaQueryWrapper\u003cIssue\u003e().eq(Issue::getId, issueId).in(Issue::getStateId, stateIds) .eq(StrUtil.isNotEmpty(sprintId), Issue::getSprintId, sprintId) .isNull(StrUtil.isEmpty(sprintId), Issue::getSprintId) .notIn(Issue::getType, IssueTypeEnum.ISSUE_TYPE_NO_NEED_SORT)); result.addAll(self); } List\u003cIssue\u003e children = issueMapper.listIssue( new LambdaQueryWrapper\u003cIssue\u003e().in(Issue::getParentId, issueId).in(Issue::getStateId, stateIds) .eq(StrUtil.isNotEmpty(sprintId), Issue::getSprintId, sprintId) .isNull(StrUtil.isEmpty(sprintId), Issue::getSprintId) .notIn(Issue::getType, IssueTypeEnum.ISSUE_TYPE_NO_NEED_SORT)); result.addAll(children); if (CollUtil.isNotEmpty(children)) { List\u003cString\u003e childrenIds = children.stream().map(Issue::getId).collect(Collectors.toList()); List\u003cIssue\u003e grandChildren = issueMapper.listIssue( new LambdaQueryWrapper\u003cIssue\u003e().in(Issue::getParentId, childrenIds).in(Issue::getStateId, stateIds) .eq(StrUtil.isNotEmpty(sprintId), Issue::getSprintId, sprintId) .isNull(StrUtil.isEmpty(sprintId), Issue::getSprintId) .notIn(Issue::getType, IssueTypeEnum.ISSUE_TYPE_NO_NEED_SORT)); result.addAll(grandChildren); } return result; } /** * 更新原泳道中的issue排序 * * @param projectId 项目id * @param sprintId 迭代id * @param sourceLane 源泳道 * @param issue 拖拽出去的工作项 */ private void updateIssueSortInSourceLane(String projectId, String sprintId, SprintLane sourceLane, Issue issue) { List\u003cString\u003e stateIdsInSourceLane = Arrays.stream(sourceLane.getStateIds().split(\",\")).collect(Collectors.toList()); List\u003cIssue\u003e issuesInSourceLane = issueMapper.listIssue( new LambdaQueryWrapper\u003cIssue\u003e().in(Issue::getStateId, stateIdsInSourceLane) .in(Issue::getProjectId, projectId) .eq(StrUtil.isNotEmpty(sprintId), Issue::getSprintId, sprintId) .isNull(StrUtil.isEmpty(sprintId), Issue::getSprintId) .notIn(Issue::getType, IssueTypeEnum.ISSUE_TYPE_NO_NEED_SORT)); //大于等于拖拽出去的工作项的sort值都要-1 issuesInSourceLane.forEach(item -\u003e { if (item.getSort() \u003e= issue.getSort() \u0026\u0026 !item.getId().equals(issue.getId())) { item.setSort(item.getSort() - 1); } }); if (CollUtil.isNotEmpty(issuesInSourceLane)) { issueService.updateBatchById(issuesInSourceLane); } } ","date":"2023-09-22","objectID":"/posts/sort-issue/:0:3","tags":["算法"],"title":"一个排序问题","uri":"/posts/sort-issue/"},{"categories":null,"content":"在Ubuntu上从源码构建wireshark最新版","date":"2023-07-05","objectID":"/posts/install-clash-on-linux/","tags":["clash","科学上网"],"title":"Deepin安装Clash for Windows","uri":"/posts/install-clash-on-linux/"},{"categories":null,"content":"前言 不知道为什么，deepin的官方App Store把Clash下架了，可能这就是网络强国的自信吧！不过本来App Store的clash一直无法安装Service Mode，索性就直接从官方仓库下载，自己制作快捷方式。 下载 从官方仓库下载压缩包并解压到指定的目录下，这里以/opt/cfw为例。 制作快捷方式 提取logo 首先，我们把下载下来的压缩包解压，然后使用如下命令把resources目录下的app.asar解压得到logo.png文件： #npx命令需要安装nodejs，见https://stackoverflow.com/questions/38523617/how-to-unpack-an-asar-file npx asar extract app.asar ./ 然后把logo保存到/home/boatrain/opt/cfw/resources/static/files/logo.png路径。 制作desktop文件 deepin的桌面快捷方式文件后缀名为desktop，所以我们在桌面新建一个名为 clash.desktop的文件，内容如下： [Desktop Entry] Name=Clash for Linux Exec=\"/home/boatrain/opt/cfw/cfw\" Type=Application Icon=/home/boatrain/opt/cfw/resources/static/files/logo.png 其中Desktop Entry表示声明该文件为快捷方式文件。Name是这个文件要显示的名字，设置了之后就可以隐藏原名称和扩展名。Exec是程序的启动脚本，或者启动指令。Type是程序类型，在开始菜单的分类中可以体现。以上四行是必须要有的参数，还有一些其他的参数不影响执行。Exec的脚本必须赋予777权限以执行。 添加到开始菜单 #把desktop文件复制到/usr/share/applications cp /home/boatrain/Desktop/clash.desktop /usr/share/applications 添加到开机自启 #把desktop文件复制到~/.config/autostart cp /home/boatrain/Desktop/clash.desktop ~/.config/autostart 参考资料 https://www.small09.top/posts/210429-deepinautorun/ ","date":"2023-07-05","objectID":"/posts/install-clash-on-linux/:0:0","tags":["clash","科学上网"],"title":"Deepin安装Clash for Windows","uri":"/posts/install-clash-on-linux/"},{"categories":null,"content":"前言 网络的所有问题都是关于路由(三层)与交换(二层)的问题，一个packet，只要弄清楚了它的四元组(src_ip，dst_ip，src_mac，dst_mac)是怎么来的，自然而然地就能理解其他问题。 ","date":"2023-04-08","objectID":"/posts/metallb_deep_dive/:0:1","tags":null,"title":"metallb浅析","uri":"/posts/metallb_deep_dive/"},{"categories":null,"content":"ARP模式 arp模式，也就是二层模式，利用的是gratuitous arp1，来向network宣告LoadBalancer的MAC地址，从而使得路由器能顺利建立起四元组。由于arp报文只存在于一个LAN内的特性，metallb的arp模式自然也就要求集群不能跨LAN。如下： 抓个包看下2: 这里的178.118.240.198就是LoadBalancer的IP，leader node通过gratuitous arp向LAN内的所有host宣告：178.118.240.198在fa:16:b2:76:f0:72。注意ARP包里的Target MAC Address不重要，取广播地址也好，取0也好，因为靠的是二层以太帧里的dst_mac来决定包的目的地。通过源码也能印证这一点： func (a *arpResponder) Gratuitous(ip net.IP) error { for _, op := range []arp.Operation{arp.OperationRequest, arp.OperationReply} { pkt, err := arp.NewPacket(op, a.hardwareAddr, ip, ethernet.Broadcast, ip) if err != nil { return fmt.Errorf(\"assembling %q gratuitous packet for %q: %s\", op, ip, err) } if err = a.conn.WriteTo(pkt, ethernet.Broadcast); err != nil { return fmt.Errorf(\"writing %q gratuitous packet for %q: %s\", op, ip, err) } stats.SentGratuitous(ip.String()) } return nil } ","date":"2023-04-08","objectID":"/posts/metallb_deep_dive/:0:2","tags":null,"title":"metallb浅析","uri":"/posts/metallb_deep_dive/"},{"categories":null,"content":"BGP模式 BGP模式算是重型武器了，因为它需要建立peer关系，所以需要路由器支持BGP。 ","date":"2023-04-08","objectID":"/posts/metallb_deep_dive/:0:3","tags":null,"title":"metallb浅析","uri":"/posts/metallb_deep_dive/"},{"categories":null,"content":"参考资料 https://github.com/metallb/metallb/issues/172 https://www.rfc-editor.org/rfc/rfc5227 https://www.wikiwand.com/en/Border_Gateway_Protocol https://www.dbi-services.com/blog/kubernetes-metallb-in-depth/ https://wiki.wireshark.org/Gratuitous_ARP.md ↩︎ https://raw.githubusercontent.com/boatrainlsz/my-image-hosting/main/202304080947706.pcap ↩︎ ","date":"2023-04-08","objectID":"/posts/metallb_deep_dive/:0:4","tags":null,"title":"metallb浅析","uri":"/posts/metallb_deep_dive/"},{"categories":null,"content":"开发环境折腾之路","date":"2022-11-19","objectID":"/posts/setup_my_development_env/","tags":["Windows","Deepin","Debian","Linux"],"title":"开发环境折腾之路","uri":"/posts/setup_my_development_env/"},{"categories":null,"content":"从Windows迁移到Deepin 因为要在Windows下学习Linux开发，但是WSL的文件系统实在是感人，详见微软官方文档的Comparing features。遂迁移到了Deepin，之所以没选择Ubuntu，还是因为Deepin做了很多开箱即用的功能，比如应用商店安装wine应用、一些很方便的小功能等，这些都减少了迁移的适配工作量。下面是一些迁移过程中踩过的坑，特此记录一下。 vpn的问题 这个已经在上一篇文章中有详细记录了，不再赘述。 Go开发环境搭建 安装Go，这没什么好说的，主要是遇到了private repo的问题，无法下载私有库。要解决这问题，要经过以下几步： 首先要先设置GOPRIVATE： go env -w GOPRIVATE='my.company.cn/*' 按照此答案设置下使用ssh，而不是http。一般来讲，这一步执行完就可以了，但是我本地的Clash始终无法安装Service Mode(这问题一直就有，详见此issue)，所以ssh流量不会走到公司的vpn里去，所以还是不行。 为了解决ssh不走vpn的问题，按照此问题的第二个回答，在~/.ssh/config中显式地设置下代理就行了： Host my.company.cn ProxyCommand nc -X connect -x 127.0.0.1:7890 %h %p ServerAliveInterval 10 安装Docker Deepin无法安装官方的Docker，安装教程见此帖。 建议切换系统为英语 当然这是个见仁见智的问题，我的需求是遇到了错误，比如执行命令出错了，英语的报错信息能很好的搜索到解决方案。中文的信息一般都是CSDN、简书这些个垃圾网站。 安装IDE 去jetbrains官方下载个toolbox，可以安装各个jetbrains家的IDE，至于免费使用，可以参考这个网站的教程。这里要注意的是，Deepin系统的很多快捷键和IDE的快捷键冲突，注意要在系统设置里修改下： 还有就是输入法的高级设置里，把那些无用的功能快捷键全关了： 不要安装Deepin 23 截止到目前，23还处于预览阶段。我装过一次，bug还是挺多的，非常影响开发体验，而且没有了应用商店，十分不便，不建议安装。 ","date":"2022-11-19","objectID":"/posts/setup_my_development_env/:0:1","tags":["Windows","Deepin","Debian","Linux"],"title":"开发环境折腾之路","uri":"/posts/setup_my_development_env/"},{"categories":null,"content":"使用openconnect客户端连接公司VPN以解决Clash冲突问题","date":"2022-07-02","objectID":"/posts/config_openconnect_to_remote_work/","tags":["vpn","Clash For Windows"],"title":"使用openconnect客户端连接公司VPN以解决Clash冲突问题","uri":"/posts/config_openconnect_to_remote_work/"},{"categories":null,"content":"环境 Deepin 20.6 ","date":"2022-07-02","objectID":"/posts/config_openconnect_to_remote_work/:0:1","tags":["vpn","Clash For Windows"],"title":"使用openconnect客户端连接公司VPN以解决Clash冲突问题","uri":"/posts/config_openconnect_to_remote_work/"},{"categories":null,"content":"目的 Cisco Anyconnect和Clash冲突，科学上网和公司vpn无法兼得，一番调查后，按照v站此帖和此issue的说法，决定换用openconnect连接vpn。 ","date":"2022-07-02","objectID":"/posts/config_openconnect_to_remote_work/:0:2","tags":["vpn","Clash For Windows"],"title":"使用openconnect客户端连接公司VPN以解决Clash冲突问题","uri":"/posts/config_openconnect_to_remote_work/"},{"categories":null,"content":"下载 从下载页下载tarball，解压缩。 ","date":"2022-07-02","objectID":"/posts/config_openconnect_to_remote_work/:0:3","tags":["vpn","Clash For Windows"],"title":"使用openconnect客户端连接公司VPN以解决Clash冲突问题","uri":"/posts/config_openconnect_to_remote_work/"},{"categories":null,"content":"安装 cd openconnect-9.01 ./configure sudo make --without-gnutls-version-check sudo make install sudo ldconfig ","date":"2022-07-02","objectID":"/posts/config_openconnect_to_remote_work/:0:4","tags":["vpn","Clash For Windows"],"title":"使用openconnect客户端连接公司VPN以解决Clash冲突问题","uri":"/posts/config_openconnect_to_remote_work/"},{"categories":null,"content":"连接登录vpn sudo openconnect $ip:$port 输入用户名和密码，并信任证书，一路yes即可 ","date":"2022-07-02","objectID":"/posts/config_openconnect_to_remote_work/:0:5","tags":["vpn","Clash For Windows"],"title":"使用openconnect客户端连接公司VPN以解决Clash冲突问题","uri":"/posts/config_openconnect_to_remote_work/"},{"categories":null,"content":"自动登录 为了免去每次都要手动信任证书和输入密码的麻烦，可以用以下命令连接： echo \"password\" | sudo openconnect $ip:$port --user=username --passwd-on-stdin --servercert $server_fingerprint 其中password为密码，server_fingerprint为服务器证书的fingerprint，可以在初次连接时看到： 为了便捷，也可以把这个命令写成shell脚本，并将shell脚本目录加入到PATH中，这样只需一个命令即可连接vpn，脚本如下： command=$1 if [ -z \"$command\" ]; then echo \"No command supplied, exit\" exit 1 fi # if command is start if [ \"$command\" == \"start\" ]; then echo \"starting vpn...\" # 这一步根据实际的配置来写 echo \"password\" | sudo openconnect $ip:$port --user=username --passwd-on-stdin --servercert $server_fingerprint \u0026 echo \"vpn started\" fi if [ \"$command\" == \"stop\" ]; then echo \"stopping vpn...\" sudo ps -ef | grep openconnect | grep 9443 | grep -v grep | awk '{print $2}' | sudo xargs kill -9 echo \"vpn stopped\" fi 将此脚本命名为vpn，注意不要带后缀.sh，假设它所在目录为/home/boatrain/tools，则可以将此路径加入到PATH中： #在~/.bashrc中添加这一行 export PATH=/home/boatrain/tools:$PATH 这里需要注意配置下执行特权命令免输入密码： echo \"`whoami` ALL=(ALL) NOPASSWD:ALL\" \u003e\u003e /etc/sudoers #不过更推荐的方式是，在 sudoers.d 目录中，创建一个新的用户规则，而不是调整可能随着系统升级，而非覆盖或者恢复默认值的系统文件： echo \"`whoami` ALL=(ALL) NOPASSWD:ALL\" | sudo tee \"/etc/sudoers.d/dont-prompt-$USER-for-sudo-password\" 这样就可以在终端中直接使用命令： vpn start vpn stop ","date":"2022-07-02","objectID":"/posts/config_openconnect_to_remote_work/:0:6","tags":["vpn","Clash For Windows"],"title":"使用openconnect客户端连接公司VPN以解决Clash冲突问题","uri":"/posts/config_openconnect_to_remote_work/"},{"categories":null,"content":"vpn与Clash的冲突问题 按照v站此帖和此issue的说法，需要将openconnect的vpn作为代理节点加入Clash才能达到科学上网和公司vpn不冲突的效果，详细研究了下，是可行的，其原理如下： 利用ocproxy在本地搭建一个proxy server 启动openconnect时，通过--script-tun选项指定所有经过proxy server的流量都进入公司vpn clash中自定义parser，配置访问公司的流量都转入proxy server 图示如下： 搭建ocproxy 克隆ocproxy到本地，先安装依赖： sudo apt-get install libevent-dev -y sudo apt-get install autoconf -y 再按照教程，本地构建二进制文件，注意最后再加上： #安装到/usr/local/bin sudo make install openconnect配置ocproxy 按照此教程，将上面写的vpn脚本进行相应修改： #省略其他部分 echo \"password\" | sudo openconnect --no-dtls --script-tun --script \"ocproxy -D 9052\" $ip:$port --user=username --passwd-on-stdin --servercert $server_fingerprint \u0026 注意，这里加了以下几个参数： --script：openconnect连接成功后执行这个脚本 --script-tun：将流量路由给上面--script参数指定的程序，这里指定流量路由给本地9052端口的ocproxy服务 --no-dtls：禁用DTLS和ESP，因为默认openconnect使用基于UDP的DTLS协议，这里不禁用的话，后续的操作无法生效，具体原因暂不清楚。欢迎指出原因 clash配置规则 我们当然可以直接在Profiles-\u003eProxies里直接增加一条Proxy，如下所示： 但是这样的话，每次更新Profile时，会覆盖本地的配置，需要重新配置一遍，这也正是这个issue所要表达的问题。按照issue里的解决办法，我们可以自定义一个parser，这样每次更新Profile完成后，再执行我们自定义的规则。按照教程，配置如下： parsers: - url: 你的机场订阅链接 yaml: prepend-rules: - DOMAIN-KEYWORD,company.domain,ocproxy - IP-CIDR,178.0.0.0/8,ocproxy - IP-CIDR,172.16.0.0/12,ocproxy append-proxies: - name: ocproxy type: socks5 server: 127.0.0.1 port: 9052 这里我简单定义了如下规则： 定义一个名为ocproxy的socks5代理，其端口为9052 域名里含有company.domain以及访问的IP在178.0.0.0/8和172.16.0.0/12范围内的请求都转发到ocproxy，当然除了DOMAIN-KEYWORD和IP-CIDR，clash支持更多匹配规则，详见rules。 配置完成后，启动vpn，更新下Profile，大功告成！ ","date":"2022-07-02","objectID":"/posts/config_openconnect_to_remote_work/:0:7","tags":["vpn","Clash For Windows"],"title":"使用openconnect客户端连接公司VPN以解决Clash冲突问题","uri":"/posts/config_openconnect_to_remote_work/"},{"categories":null,"content":"参考资料 https://www.infradead.org/openconnect/download.html https://www.infradead.org/openconnect/connecting.html https://askubuntu.com/questions/1043024/how-to-run-openconnect-with-username-and-password-in-a-line-in-the-terminal https://github.com/Fndroid/clash_for_windows_pkg/issues/988 https://www.v2ex.com/t/775773 https://www.monperrus.net/martin/ssh-over-vpn-with-openconnect https://github.com/cernekee/ocproxy ","date":"2022-07-02","objectID":"/posts/config_openconnect_to_remote_work/:0:8","tags":["vpn","Clash For Windows"],"title":"使用openconnect客户端连接公司VPN以解决Clash冲突问题","uri":"/posts/config_openconnect_to_remote_work/"},{"categories":null,"content":"在Ubuntu上从源码构建wireshark最新版","date":"2022-06-27","objectID":"/posts/build_wireshark_from_source/","tags":["shell","wireshark","cmake"],"title":"在Ubuntu上从源码构建最新版wireshark","uri":"/posts/build_wireshark_from_source/"},{"categories":null,"content":"Deepin 20.6同样适用 ","date":"2022-06-27","objectID":"/posts/build_wireshark_from_source/:0:0","tags":["shell","wireshark","cmake"],"title":"在Ubuntu上从源码构建最新版wireshark","uri":"/posts/build_wireshark_from_source/"},{"categories":null,"content":"下载源码 git clone https://gitlab.com/wireshark/wireshark.git ","date":"2022-06-27","objectID":"/posts/build_wireshark_from_source/:0:1","tags":["shell","wireshark","cmake"],"title":"在Ubuntu上从源码构建最新版wireshark","uri":"/posts/build_wireshark_from_source/"},{"categories":null,"content":"安装依赖项 sudo apt-get install flex g++ gcc perl python3 cmake build-essential -y ","date":"2022-06-27","objectID":"/posts/build_wireshark_from_source/:0:2","tags":["shell","wireshark","cmake"],"title":"在Ubuntu上从源码构建最新版wireshark","uri":"/posts/build_wireshark_from_source/"},{"categories":null,"content":"执行设置脚本 cd wireshark tools/debian-setup.sh --install-optional --install-deb-deps ","date":"2022-06-27","objectID":"/posts/build_wireshark_from_source/:0:3","tags":["shell","wireshark","cmake"],"title":"在Ubuntu上从源码构建最新版wireshark","uri":"/posts/build_wireshark_from_source/"},{"categories":null,"content":"安装 cd wireshark cmake . make make install ","date":"2022-06-27","objectID":"/posts/build_wireshark_from_source/:0:4","tags":["shell","wireshark","cmake"],"title":"在Ubuntu上从源码构建最新版wireshark","uri":"/posts/build_wireshark_from_source/"},{"categories":null,"content":"启动 wireshark 此时wireshark启动成功： ","date":"2022-06-27","objectID":"/posts/build_wireshark_from_source/:0:5","tags":["shell","wireshark","cmake"],"title":"在Ubuntu上从源码构建最新版wireshark","uri":"/posts/build_wireshark_from_source/"},{"categories":null,"content":"参考资料 https://www.wireshark.org/docs/wsug_html_chunked/ChBuildInstallUnixBuild.html ","date":"2022-06-27","objectID":"/posts/build_wireshark_from_source/:0:6","tags":["shell","wireshark","cmake"],"title":"在Ubuntu上从源码构建最新版wireshark","uri":"/posts/build_wireshark_from_source/"},{"categories":null,"content":"IDEA本地搭建pulsar调试环境","date":"2022-05-27","objectID":"/posts/pulsar_debug_in_ide/","tags":["Pulsar"],"title":"IDEA本地搭建Pulsar调试环境","uri":"/posts/pulsar_debug_in_ide/"},{"categories":null,"content":"部署zookeeper 本地debug部署个单机版的就够了，参考此教程。注意在zoo.cfg文件中配置下admin.serverPort，默认是8080端口，会和Pulsar Broker的默认HTTP端口冲突，这里改为8888端口，完整配置如下： # The number of milliseconds of each tick tickTime=2000 # The number of ticks that the initial # synchronization phase can take initLimit=10 # The number of ticks that can pass between # sending a request and getting an acknowledgement syncLimit=5 # the directory where the snapshot is stored. # do not use /tmp for storage, /tmp here is just # example sakes. dataDir=/tmp/zookeeper # the port at which the clients will connect clientPort=2181 # the maximum number of client connections. # increase this if you need to handle more clients #maxClientCnxns=60 # # Be sure to read the maintenance section of the # administrator guide before turning on autopurge. # # http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance # # The number of snapshots to retain in dataDir #autopurge.snapRetainCount=3 # Purge task interval in hours # Set to \"0\" to disable auto purge feature #autopurge.purgeInterval=1 ## Metrics Providers # # https://prometheus.io Metrics Exporter #metricsProvider.className=org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider #metricsProvider.httpPort=7000 #metricsProvider.exportJvmInfo=true admin.serverPort=8888 ","date":"2022-05-27","objectID":"/posts/pulsar_debug_in_ide/:1:0","tags":["Pulsar"],"title":"IDEA本地搭建Pulsar调试环境","uri":"/posts/pulsar_debug_in_ide/"},{"categories":null,"content":"启动broker 在conf/broker.conf配置文件中，将metadataStoreUrl改为上一步中启动的zk的地址localhost:2181，如下： # The metadata store URL # Examples: # * zk:my-zk-1:2181,my-zk-2:2181,my-zk-3:2181 # * my-zk-1:2181,my-zk-2:2181,my-zk-3:2181 (will default to ZooKeeper when the schema is not specified) # * zk:my-zk-1:2181,my-zk-2:2181,my-zk-3:2181/my-chroot-path (to add a ZK chroot path) metadataStoreUrl=zk:localhost:2181 ","date":"2022-05-27","objectID":"/posts/pulsar_debug_in_ide/:2:0","tags":["Pulsar"],"title":"IDEA本地搭建Pulsar调试环境","uri":"/posts/pulsar_debug_in_ide/"},{"categories":null,"content":"创建Pulsar Cluster 找到PulsarAdminTool类，运行配置如下： conf/client.conf --admin-url http://localhost:8080 clusters create cluster-1 ","date":"2022-05-27","objectID":"/posts/pulsar_debug_in_ide/:3:0","tags":["Pulsar"],"title":"IDEA本地搭建Pulsar调试环境","uri":"/posts/pulsar_debug_in_ide/"},{"categories":null,"content":"创建tenant 找到PulsarAdminTool类，创建名为public的租户，运行配置如下： conf/client.conf --admin-url http://localhost:8080 tenants create public ","date":"2022-05-27","objectID":"/posts/pulsar_debug_in_ide/:4:0","tags":["Pulsar"],"title":"IDEA本地搭建Pulsar调试环境","uri":"/posts/pulsar_debug_in_ide/"},{"categories":null,"content":"创建namespace 找到PulsarAdminTool类，在public租户下创建名为default的namespace，运行配置如下： conf/client.conf --admin-url http://localhost:8080 namespaces create public/default ","date":"2022-05-27","objectID":"/posts/pulsar_debug_in_ide/:5:0","tags":["Pulsar"],"title":"IDEA本地搭建Pulsar调试环境","uri":"/posts/pulsar_debug_in_ide/"},{"categories":null,"content":"消费者消费消息 找到PulsarClientTool类，接收非持久化消息，运行配置如下： conf/client.conf consume non-persistent://public/default/example-np-topic --subscription-name np-sub ","date":"2022-05-27","objectID":"/posts/pulsar_debug_in_ide/:6:0","tags":["Pulsar"],"title":"IDEA本地搭建Pulsar调试环境","uri":"/posts/pulsar_debug_in_ide/"},{"categories":null,"content":"生产者发送消息 找到PulsarClientTool类，发送一个非持久化消息，运行配置如下： conf/client.conf produce non-persistent://public/default/example-np-topic --num-produce 1 --messages \"This message will be stored only in memory\" 此时会在consumer的控制台看到日志打印，说明成功收到了消息： ","date":"2022-05-27","objectID":"/posts/pulsar_debug_in_ide/:7:0","tags":["Pulsar"],"title":"IDEA本地搭建Pulsar调试环境","uri":"/posts/pulsar_debug_in_ide/"},{"categories":null,"content":"生产消费持久化消息 以上步骤介绍的是非持久化消息的生产和消费，持久化消息需要BookKeeper。不论是从源码编译，还是直接安装，BookKeeper目前均不支持Windows，具体见此issue，可以在WSL中编译。这里不涉及BookKeeper源码的debug，就直接按照官方教程安装。 ","date":"2022-05-27","objectID":"/posts/pulsar_debug_in_ide/:8:0","tags":["Pulsar"],"title":"IDEA本地搭建Pulsar调试环境","uri":"/posts/pulsar_debug_in_ide/"},{"categories":null,"content":"下载bk压缩包 从https://bookkeeper.apache.org/releases下载压缩包，解压。 ","date":"2022-05-27","objectID":"/posts/pulsar_debug_in_ide/:8:1","tags":["Pulsar"],"title":"IDEA本地搭建Pulsar调试环境","uri":"/posts/pulsar_debug_in_ide/"},{"categories":null,"content":"单机部署bk 在本地单机部署时，需要运行localbookie命令，详见https://bookkeeper.apache.org/docs/getting-started/run-locally。这里会出现两个问题： 无法启动JVM，报错日志如下： Unrecognized VM option 'PrintGCDateStamps' Error: Could not create the Java Virtual Machine. Error: A fatal exception has occurred. Program will exit. 这个问题，在这里有提及。我们直接在启动脚本bookkeeper中加一下-XX:+IgnoreUnrecognizedVMOptions即可： ... elif [ ${COMMAND} == \"localbookie\" ]; then NUMBER=$1 shift exec ${JAVA} ${OPTS} ${JMX_ARGS} -XX:+IgnoreUnrecognizedVMOptions -Dzookeeper.4lw.commands.whitelist='*' org.apache.bookkeeper.util.LocalBookKeeper ${NUMBER} ${BOOKIE_CONF} $@ ... 信息 此问题，我在bookkeeper官方仓库中提了个issue 2181端口绑定失败，这是因为单机版本的bk会自己创建并启动一个zk server，与文章开头我们自己创建的zk冲突了，停掉我们自己创建的zk即可。 ","date":"2022-05-27","objectID":"/posts/pulsar_debug_in_ide/:8:2","tags":["Pulsar"],"title":"IDEA本地搭建Pulsar调试环境","uri":"/posts/pulsar_debug_in_ide/"},{"categories":null,"content":"消费者消费持久化消息 conf/client.conf consume persistent://public/default/example-topic --subscription-name p-sub ","date":"2022-05-27","objectID":"/posts/pulsar_debug_in_ide/:8:3","tags":["Pulsar"],"title":"IDEA本地搭建Pulsar调试环境","uri":"/posts/pulsar_debug_in_ide/"},{"categories":null,"content":"生产者生产持久化消息 conf/client.conf produce persistent://public/default/example-topic --num-produce 1 --messages \"This message will be stored in bk\" ","date":"2022-05-27","objectID":"/posts/pulsar_debug_in_ide/:8:4","tags":["Pulsar"],"title":"IDEA本地搭建Pulsar调试环境","uri":"/posts/pulsar_debug_in_ide/"},{"categories":null,"content":"独立版的Pulsar 根据Pulsar官方文档的描述，独立版的Pulsar用来本地开发和测试： 引用 For local development and testing, you can run Pulsar in standalone mode on your machine. The standalone mode includes a Pulsar broker, the necessary RocksDB and BookKeeper components running inside of a single Java Virtual Machine (JVM) process. 独立版Pulsar的启动类是org.apache.pulsar.PulsarStandaloneStarter，这里踩了个坑：由于项目放在C盘，启动时创建RocksDB相关的文件时，会报权限不足的错： 2022-06-03T10:39:29,275 - ERROR - [io-write-scheduler-OrderedScheduler-0-0:RocksdbKVStore@195] - Failed to restore checkpoint: Checkpoint{ID='3014ae6e-5297-45aa-b688-2450d309691f', createdAt: 0 null} org.apache.bookkeeper.statelib.api.exceptions.StateStoreException: Failed to create dir 000000000000000000/000000000000000000/000000000000000000 at org.apache.bookkeeper.statelib.impl.rocksdb.checkpoint.CheckpointInfo$1.restore(CheckpointInfo.java:81) ~[statelib-4.15.0.jar:4.15.0] at org.apache.bookkeeper.statelib.impl.kv.RocksdbKVStore.loadRocksdbFromCheckpointStore(RocksdbKVStore.java:184) ~[statelib-4.15.0.jar:4.15.0] at org.apache.bookkeeper.statelib.impl.kv.RocksdbKVStore.init(RocksdbKVStore.java:286) ~[statelib-4.15.0.jar:4.15.0] at org.apache.bookkeeper.statelib.impl.journal.AbstractStateStoreWithJournal.lambda$initializeLocalStore$5(AbstractStateStoreWithJournal.java:216) ~[statelib-4.15.0.jar:4.15.0] at org.apache.bookkeeper.statelib.impl.journal.AbstractStateStoreWithJournal.lambda$executeIO$17(AbstractStateStoreWithJournal.java:526) ~[statelib-4.15.0.jar:4.15.0] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?] at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:131) [guava-31.0.1-jre.jar:?] at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:74) [guava-31.0.1-jre.jar:?] at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:82) [guava-31.0.1-jre.jar:?] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) [?:?] at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304) [?:?] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) [?:?] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) [?:?] at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) [netty-common-4.1.76.Final.jar:4.1.76.Final] at java.lang.Thread.run(Thread.java:833) [?:?] Caused by: java.nio.file.FileSystemException: C:\\Users\\boatrain\\research\\pulsar\\data\\standalone\\bookkeeper\\ranges\\data\\ranges\\000000000000000000\\000000000000000000\\000000000000000000\\current: A required privilege is not held by the client at sun.nio.fs.WindowsException.translateToIOException(WindowsException.java:92) ~[?:?] at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:103) ~[?:?] at sun.nio.fs.WindowsException.rethrowAsIOException(WindowsException.java:108) ~[?:?] at sun.nio.fs.WindowsFileSystemProvider.createSymbolicLink(WindowsFileSystemProvider.java:598) ~[?:?] at java.nio.file.Files.createSymbolicLink(Files.java:1069) ~[?:?] at org.apache.bookkeeper.statelib.impl.rocksdb.checkpoint.CheckpointInfo.updateCurrent(CheckpointInfo.java:126) ~[statelib-4.15.0.jar:4.15.0] at org.apache.bookkeeper.statelib.impl.rocksdb.checkpoint.CheckpointInfo$1.restore(CheckpointInfo.java:79) ~[statelib-4.15.0.jar:4.15.0] ... 15 more 解决方法就是以管理员启动IDEA，然后再启动org.apache.pulsar.PulsarStandaloneStarter： ","date":"2022-05-27","objectID":"/posts/pulsar_debug_in_ide/:9:0","tags":["Pulsar"],"title":"IDEA本地搭建Pulsar调试环境","uri":"/posts/pulsar_debug_in_ide/"},{"categories":null,"content":"Apache Pulsar in Action第二章读书笔记","date":"2022-05-18","objectID":"/posts/pulsar_in_action_ch02/","tags":["Pulsar"],"title":"Apache Pulsar in Action第二章读书笔记","uri":"/posts/pulsar_in_action_ch02/"},{"categories":null,"content":"订阅(subscription) 每个订阅都有描述它的元数据，存放在Pulsar的Zookeeper中，包括但不限于： 此订阅的所有消费者的http地址 游标(cursor)，代表了此订阅下，最后一个被消费且被确认了的消息的位置 ","date":"2022-05-18","objectID":"/posts/pulsar_in_action_ch02/:1:0","tags":["Pulsar"],"title":"Apache Pulsar in Action第二章读书笔记","uri":"/posts/pulsar_in_action_ch02/"},{"categories":null,"content":"订阅模式 以一家股票数据分析公司为例 exclusive 独占模式，订阅的消息只能由一个消费者消费，多余的消费者想要订阅到此topic，会报错。适用场景：有序，且每个消息只能被一个消费者消费一次： failover 故障转移模式，高可用版的exclusive，一个挂了，备份顶上，继续消费： shared 每个订阅都有消息的副本，而订阅使用轮询模式投递给订阅下的消费者，适用于实现工作队列，因为顺序不重要，可以扩展消费者个数以提高消费能力： key-shared 相当于SQL中的GROUP BY，对消息以某个key作为分组依据，进行分组，然后投递给不同的消费者，如下图所示，Oracle的股票数据让Consumer-C处理，Microsoft的股票数据让Consumer-A处理，Amazon的股票数据让Consumer-B处理，这里的分组依据就是股票代码： ","date":"2022-05-18","objectID":"/posts/pulsar_in_action_ch02/:1:1","tags":["Pulsar"],"title":"Apache Pulsar in Action第二章读书笔记","uri":"/posts/pulsar_in_action_ch02/"},{"categories":null,"content":"消息保留与过期策略 ","date":"2022-05-18","objectID":"/posts/pulsar_in_action_ch02/:2:0","tags":["Pulsar"],"title":"Apache Pulsar in Action第二章读书笔记","uri":"/posts/pulsar_in_action_ch02/"},{"categories":null,"content":"broker级别的消息保留策略 消息默认的保留策略是：所有topic的消费者都确认了这条消息，那这条消息就会被删除。保留策略可由defaultRetentionTimeInMinutes和defaultRetentionSizeInMB参数控制，这两个参数都是broker级别的，在broker的配置文件中配置，默认都是0，代表一旦消息被确认，就会被删除。 ","date":"2022-05-18","objectID":"/posts/pulsar_in_action_ch02/:2:1","tags":["Pulsar"],"title":"Apache Pulsar in Action第二章读书笔记","uri":"/posts/pulsar_in_action_ch02/"},{"categories":null,"content":"namespace级别的消息保留策略 Pulsar支持在namespace级别覆盖broker级别的消息保留策略： ","date":"2022-05-18","objectID":"/posts/pulsar_in_action_ch02/:2:2","tags":["Pulsar"],"title":"Apache Pulsar in Action第二章读书笔记","uri":"/posts/pulsar_in_action_ch02/"},{"categories":null,"content":"消息积压策略 消息积压就是消费者的消费速度跟不上生产者的生产速度，造成了积压： Pulsar默认会一直保留未被确认的消息，但是可以在namespace级别改变这一设置，消息积压策略和上一节的消息保留策略类似，只不过前者配置的是未确认消息的保留策略，后者是已确认消息的保留策略。积压策略有三种： producer_request_hold策略，给生产者发送异常，提示生产者应该暂停发送。适用于生产者显式捕获异常并稍后重试的场景 producer_exception策略，强制断开生产者连接。适用于资源敏感的场景，比如某些内存有限的设备上，及时断开连接，节省资源 consumer_backlog_eviction策略，此策略不影响生产者，旧的未被确认的消息将被删除，这会造成消息丢失 ","date":"2022-05-18","objectID":"/posts/pulsar_in_action_ch02/:2:3","tags":["Pulsar"],"title":"Apache Pulsar in Action第二章读书笔记","uri":"/posts/pulsar_in_action_ch02/"},{"categories":null,"content":"消息过期策略 消息过期策略在消费者更关心最新数据的情况下经常用到，比如坐网约车，乘客更关心司机的最新位置，而不是5分钟前的位置，如下所示，将E-payments/payments namespace下的消息存活时间设置为120秒： ","date":"2022-05-18","objectID":"/posts/pulsar_in_action_ch02/:2:4","tags":["Pulsar"],"title":"Apache Pulsar in Action第二章读书笔记","uri":"/posts/pulsar_in_action_ch02/"},{"categories":null,"content":"消息保留策略、消息过期策略、消息积压策略的关系 消息保留策略针对已被确认的消息，消息积压策略针对未被确认的消息，其中，存活时间超过了TTL的消息将被删： 消息保留策略可以结合下面要讲的层级存储来实现无限容量的存储。 ","date":"2022-05-18","objectID":"/posts/pulsar_in_action_ch02/:2:5","tags":["Pulsar"],"title":"Apache Pulsar in Action第二章读书笔记","uri":"/posts/pulsar_in_action_ch02/"},{"categories":null,"content":"用latex画出源代码与其汇编代码的关系图","date":"2022-04-20","objectID":"/posts/latex-research/","tags":["LaTex"],"title":"用latex画出源代码与其汇编代码的关系图","uri":"/posts/latex-research/"},{"categories":null,"content":"最近在看《程序员的自我修养》，看到静态链接这一章，看到elf文件的内存布局。由于纸质书的限制，经常看到后面的汇编，就忘了前面的源代码。所以尝试用画图的形式记录下来，一来加深记忆，二来使其更加明晰。当然最简单的方式就是分别截两个图，然后画个箭头就行了，但尝试下来，清晰度感人，而后又尝试了adobe illustrator，也不尽如人意。偶然在知乎看到这个帖子，感觉是我想要的，于是按照这个教程装上了texlive和vscode（上次用texlive还是大学时写论文用到），一番Google后又搜到这个教程，应该可行。先记录下，有时间继续更新。 初步效果： 初步效果 latex代码： \\documentclass[border={35pt 10pt 150pt 60pt},svgnames]{standalone} \\usepackage{tikz} \\usetikzlibrary{positioning, calc, matrix, arrows.meta} \\usepackage{listings} \\usepackage{parcolumns} \\lstset{% frame = tb, % draw frame at top and bottom of code block tabsize = 1, % tab space width numbers = left, % display line numbers on the left framesep = 3pt, % expand outward framerule = 0.4pt, % expand outward commentstyle = \\color{Green}, % comment color keywordstyle = \\color{blue}, % keyword color stringstyle = \\color{DarkRed}, % string color backgroundcolor = \\color{WhiteSmoke}, % backgroundcolor color showstringspaces = false, % do not mark spaces in strings breaklines=true, postbreak=\\mbox{\\textcolor{red}{$\\hookrightarrow$}\\space}, } \\begin{document} \\begin{minipage}[t]{1.2\\linewidth} \\begin{lstlisting}[language = C, numbers = none, escapechar = !, basicstyle = \\ttfamily\\bfseries, linewidth = 1.2\\linewidth] int printf! \\tikz[remember picture] \\node [] (printf) {};!(const char *format, ...); int global_init_var = !\\tikz[remember picture] \\node [] (global_init_var) {};!84; int global_uninit_var; void func1(int i) { printf(!\\tikz[remember picture] \\node [] (placeholder) {};!\"%d\\n\", i); } int main(void) { static int static_var = !\\tikz[remember picture] \\node [] (static_var) {};!85; static int static_var2; int a = 1; int b; func1(static_var + static_var2 + a + b); return a; } \\end{lstlisting} \\end{minipage} \\qquad \\begin{minipage}[t]{1.2\\linewidth} \\begin{lstlisting}[numbers = none, escapechar = !, basicstyle = \\ttfamily\\bfseries, linewidth = 1.4\\linewidth] main.o: file format elf64-x86-64 Contents of section .text: 0000 f30f1efa 554889e5 4883ec10 897dfc8b 0010 45fc89c6 488d3d00 000000b8 00000000 0020 e8000000 0090c9c3 f30f1efa 554889e5 0030 4883ec10 c745f801 0000008b 15000000 0040 008b0500 00000001 c28b45f8 01c28b45 0050 fc01d089 c7e80000 00008b45 f8c9c3 Contents of section .data: 0000 !\\tikz[remember picture] \\node [] (global_init_var_hex) {};!54000000 !\\tikz[remember picture] \\node [] (static_var_hex) {};!55000000 Contents of section .rodata: 0000 !\\tikz[remember picture] \\node [] (placeholder_hex) {};!25640a00 ...... Disassembly of section .text: 0000000000000000 \u003cfunc1\u003e: 0: f3 0f 1e fa endbr64 4: 55 push %rbp 5: 48 89 e5 mov %rsp,%rbp 8: 48 83 ec 10 sub $0x10,%rsp c: 89 7d fc mov %edi,-0x4(%rbp) f: 8b 45 fc mov -0x4(%rbp),%eax 12: 89 c6 mov %eax,%esi 14: 48 8d 3d 00 00 00 00 lea 0x0(%rip),%rdi # 1b \u003cfunc1+0x1b\u003e 1b: b8 00 00 00 00 mov $0x0,%eax 20: e8 00 00 00 00 call 25 \u003cfunc1+0x25\u003e 25: 90 nop 26: c9 leave 27: c3 ret 0000000000000028 \u003cmain\u003e: 28: f3 0f 1e fa endbr64 2c: 55 push %rbp 2d: 48 89 e5 mov %rsp,%rbp 30: 48 83 ec 10 sub $0x10,%rsp 34: c7 45 f8 01 00 00 00 movl $0x1,-0x8(%rbp) 3b: 8b 15 00 00 00 00 mov 0x0(%rip),%edx # 41 \u003cmain+0x19\u003e 41: 8b 05 00 00 00 00 mov 0x0(%rip),%eax # 47 \u003cmain+0x1f\u003e 47: 01 c2 add %eax,%edx 49: 8b 45 f8 mov -0x8(%rbp),%eax 4c: 01 c2 add %eax,%edx 4e: 8b 45 fc mov -0x4(%rbp),%eax 51: 01 d0 add %edx,%eax 53: 89 c7 mov %eax,%edi 55: e8 00 00 00 00 call 5a \u003cmain+0x32\u003e 5a: 8b 45 f8 mov -0x8(%rbp),%eax 5d: c9 leave 5e: c3 ret \\end{lstlisting} \\end{minipage} \\begin{tikzpicture}[remember picture, overlay, every node/.append style = { align = center, minimum height = 10pt, font = \\bfseries, fill= green!20}, text width = 2.5cm ] \\draw[-\u003e,red,line width=1pt] (global_init_var) edge [in=195, out=-30] (global_init_var_hex); \\draw[-\u003e,blue,line width=1pt] (static_var) edge [in=195, out=-30] (static_var_hex); \\draw[-\u003e,purple,line width=1pt] (placeholder) edge [in=195, out=-20] (placeholder_hex); \\end{tikzpicture} \\end{document} ","date":"2022-04-20","objectID":"/posts/latex-research/:0:0","tags":["LaTex"],"title":"用latex画出源代码与其汇编代码的关系图","uri":"/posts/latex-research/"},{"categories":null,"content":"参考资料： https://stuff.mit.edu/afs/athena/contrib/tex-contrib/beamer/pgf-1.01/doc/generic/pgf/version-for-tex4ht/en/pgfmanualse8.html https://www.overleaf.com/learn/latex/TikZ_package https://github.com/anvithks/hugo-embed-pdf-shortcode#setup https://tex.stackexchange.com/questions/222991/formatting-columns-with-multicols-and-lstlisting https://stackoverflow.com/questions/6605006/convert-pdf-to-image-with-high-resolution ","date":"2022-04-20","objectID":"/posts/latex-research/:0:1","tags":["LaTex"],"title":"用latex画出源代码与其汇编代码的关系图","uri":"/posts/latex-research/"},{"categories":null,"content":"《程序员的自我修养》第三章——目标文件里有什么","date":"2022-04-11","objectID":"/posts/self-cultivation-of-programmer-ch03/","tags":["程序员的自我修养"],"title":"《程序员的自我修养》第三章——目标文件里有什么","uri":"/posts/self-cultivation-of-programmer-ch03/"},{"categories":null,"content":"示例代码(main.c) int printf(const char *format, ...); int global_init_var = 84; int global_uninit_var; void func1(int i) { printf(\"%d\\n\", i); } int main(void) { static int static_var = 85; static int static_var2; int a = 1; int b; func1(static_var + static_var2 + a + b); return a; } ","date":"2022-04-11","objectID":"/posts/self-cultivation-of-programmer-ch03/:0:1","tags":["程序员的自我修养"],"title":"《程序员的自我修养》第三章——目标文件里有什么","uri":"/posts/self-cultivation-of-programmer-ch03/"},{"categories":null,"content":"查看目标文件 gcc -c main.c objdump -s -d main.o ","date":"2022-04-11","objectID":"/posts/self-cultivation-of-programmer-ch03/:0:2","tags":["程序员的自我修养"],"title":"《程序员的自我修养》第三章——目标文件里有什么","uri":"/posts/self-cultivation-of-programmer-ch03/"},{"categories":null,"content":"目标文件内容 ","date":"2022-04-11","objectID":"/posts/self-cultivation-of-programmer-ch03/:0:3","tags":["程序员的自我修养"],"title":"《程序员的自我修养》第三章——目标文件里有什么","uri":"/posts/self-cultivation-of-programmer-ch03/"},{"categories":null,"content":"代码与目标文件对应关系 代码段 存放func1函数和main函数的代码 Contents of section .text: 0000 f30f1efa 554889e5 4883ec10 897dfc8b ....UH..H....}.. 0010 45fc89c6 488d3d00 000000b8 00000000 E...H.=......... 0020 e8000000 0090c9c3 f30f1efa 554889e5 ............UH.. 0030 4883ec10 c745f801 0000008b 15000000 H....E.......... 0040 008b0500 00000001 c28b45f8 01c28b45 ..........E....E 0050 fc01d089 c7e80000 00008b45 f8c9c3 ...........E... ...... Disassembly of section .text: 0000000000000000 \u003cfunc1\u003e: 0: f3 0f 1e fa endbr64 4: 55 push %rbp 5: 48 89 e5 mov %rsp,%rbp 8: 48 83 ec 10 sub $0x10,%rsp c: 89 7d fc mov %edi,-0x4(%rbp) f: 8b 45 fc mov -0x4(%rbp),%eax 12: 89 c6 mov %eax,%esi 14: 48 8d 3d 00 00 00 00 lea 0x0(%rip),%rdi # 1b \u003cfunc1+0x1b\u003e 1b: b8 00 00 00 00 mov $0x0,%eax 20: e8 00 00 00 00 callq 25 \u003cfunc1+0x25\u003e 25: 90 nop 26: c9 leaveq 27: c3 retq 0000000000000028 \u003cmain\u003e: 28: f3 0f 1e fa endbr64 2c: 55 push %rbp 2d: 48 89 e5 mov %rsp,%rbp 30: 48 83 ec 10 sub $0x10,%rsp 34: c7 45 f8 01 00 00 00 movl $0x1,-0x8(%rbp) 3b: 8b 15 00 00 00 00 mov 0x0(%rip),%edx # 41 \u003cmain+0x19\u003e 41: 8b 05 00 00 00 00 mov 0x0(%rip),%eax # 47 \u003cmain+0x1f\u003e 47: 01 c2 add %eax,%edx 49: 8b 45 f8 mov -0x8(%rbp),%eax 4c: 01 c2 add %eax,%edx 4e: 8b 45 fc mov -0x4(%rbp),%eax 51: 01 d0 add %edx,%eax 53: 89 c7 mov %eax,%edi 55: e8 00 00 00 00 callq 5a \u003cmain+0x32\u003e 5a: 8b 45 f8 mov -0x8(%rbp),%eax 5d: c9 leaveq 5e: c3 retq 数据段 存放初始化了的全局静态变量和局部静态变量，比如这里0x54000000和0x55000000和就分别是代码中的int global_init_var = 84;和static int static_var = 85;，注意用的是大端序。 Contents of section .data: 0000 54000000 55000000 T...U... 只读数据段 存放只读数据，比如const变量和字符串常量，比如这里0x25640a00就是printf函数用到的字符串常量\"%d\\n\" Contents of section .rodata: 0000 25640a00 %d.. BSS段 存放未初始化的全局静态变量和局部静态变量，比如代码中的global_uninit_var和static_var2 总结 总结 ","date":"2022-04-11","objectID":"/posts/self-cultivation-of-programmer-ch03/:0:4","tags":["程序员的自我修养"],"title":"《程序员的自我修养》第三章——目标文件里有什么","uri":"/posts/self-cultivation-of-programmer-ch03/"},{"categories":null,"content":"平时常用到的一些脚本","date":"2022-04-07","objectID":"/posts/common_scripts/","tags":["shell","python","powershell"],"title":"平时常用到的一些脚本","uri":"/posts/common_scripts/"},{"categories":null,"content":"整理一下平时常用到的一些脚本 ","date":"2022-04-07","objectID":"/posts/common_scripts/:0:0","tags":["shell","python","powershell"],"title":"平时常用到的一些脚本","uri":"/posts/common_scripts/"},{"categories":null,"content":"批量删除docker镜像 ###删除mariadb的所有镜像 ###方法1 docker images|grep mariadb | awk 'BEGIN{OFS=\":\"} {print $1,$2}' | while read line; do docker rmi -f $line done ###方法2：不用read line也可以做到的 docker rmi -f `docker images |grep mariadb |awk '{print $3}'` ","date":"2022-04-07","objectID":"/posts/common_scripts/:0:1","tags":["shell","python","powershell"],"title":"平时常用到的一些脚本","uri":"/posts/common_scripts/"},{"categories":null,"content":"对目录下所有shell脚本运行dos2unix命令 find . -type f -name \"*.sh\" -print0 | xargs -0 dos2unix ","date":"2022-04-07","objectID":"/posts/common_scripts/:0:2","tags":["shell","python","powershell"],"title":"平时常用到的一些脚本","uri":"/posts/common_scripts/"},{"categories":null,"content":"trivy共享漏洞数据库","date":"2022-04-06","objectID":"/posts/trivy_share_db/","tags":["trivy","GVE"],"title":"trivy共享漏洞数据库","uri":"/posts/trivy_share_db/"},{"categories":null,"content":"需求 已经在一台机器上安装了trivy，并下载了漏洞数据库。需要在另一台上也使用同版本的数据库，而不是去更新，因为初始化时，trivy都需要强制更新。 ","date":"2022-04-06","objectID":"/posts/trivy_share_db/:0:1","tags":["trivy","GVE"],"title":"trivy共享漏洞数据库","uri":"/posts/trivy_share_db/"},{"categories":null,"content":"实现 在官方issue列表中找到了类似的需求，于是可以这样实现： 在已安装trivy的机器上执行trivy -h命令，找到默认的cache目录，漏洞数据库就存放在这里 ##trivy -h |grep cache --cache-dir value cache directory (default: \"/root/.cache/trivy\") [$TRIVY_CACHE_DIR] 将/root/.cache/trivy文件夹复制到另一台机器上的相同路径下 在另一台机器上执行如下命令，即可进行扫描，且不会更新漏洞数据库 trivy --cache-dir /root/.cache/trivy image --skip-update --severity HIGH,CRITICAL $your_image ","date":"2022-04-06","objectID":"/posts/trivy_share_db/:0:2","tags":["trivy","GVE"],"title":"trivy共享漏洞数据库","uri":"/posts/trivy_share_db/"},{"categories":null,"content":"《计算机系统要素》第一章——布尔逻辑","date":"2022-04-05","objectID":"/posts/the-elements-of-computing-systems-ch01/","tags":["计算机系统要素"],"title":"《计算机系统要素》第一章——布尔逻辑","uri":"/posts/the-elements-of-computing-systems-ch01/"},{"categories":null,"content":"JDK元空间的内存分配体系","date":"2022-04-03","objectID":"/posts/jvm_metaspace_improvement/","tags":["java","metaspace"],"title":"JDK元空间的内存分配体系","uri":"/posts/jvm_metaspace_improvement/"},{"categories":null,"content":" 这是去年写在语雀上的文章，搬运过来。 前段时间偶然在Twitter看到了SAP工程师的一个分享，这位大佬给OpenJDK提了个JEP，几乎算是重构了JDK元空间的实现，使得JDK的元空间更有弹性，对内存占用更友好，于是花了点时间看了下他的系列文章。简单整理如下： ","date":"2022-04-03","objectID":"/posts/jvm_metaspace_improvement/:0:0","tags":["java","metaspace"],"title":"JDK元空间的内存分配体系","uri":"/posts/jvm_metaspace_improvement/"},{"categories":null,"content":"版本说明 从JDK8以来，元空间的实现方式发生了很大变化，这里以OpenJDK 11为准。 ","date":"2022-04-03","objectID":"/posts/jvm_metaspace_improvement/:0:1","tags":["java","metaspace"],"title":"JDK元空间的内存分配体系","uri":"/posts/jvm_metaspace_improvement/"},{"categories":null,"content":"1. 什么是元空间 详见此文，简单来讲，Metaspace是存储类元数据的地方，我们知道在JDK 8之前，类的元数据都是存在堆中的永久代。JDK8后，永久代被废除，元数据都移到了Metaspace里。类的元数据大体可以看做class文件的运行时形式，包括但不限于： Klass结构：JVM内部对Java Class的表示，其中含有vtable和itable 方法的元数据：method_info的运行时形式，其中有字节码，异常表，常量等 常量池 注解 方法计数器：为了给JIT编译器提供数据 其他数据 元空间何时分配 当一个类被加载完成且它的JVM内部表示已经准备就绪了，它的类加载器就会给它分配对应的元空间： 元空间何时释放 对一个类来说，已分配的元空间被它的类加载器所持有，当且仅当类加载器自身被卸载了，对应的元空间才会被回收掉。也就是说：当且仅当这个类加载器没有被引用且被它加载的类的所有实例也没有被引用时，对应的元空间才会被回收 但是要注意的是，这里说的释放，不是指将内存还给操作系统，被释放的内存，一部分甚至是全部，会以free-list的形式保留，以供后续的类加载时候用。至于到底有多少内存会被保留，取决于元空间的碎片化程度，OpenJDK 11元空间的碎片化问题做了很多修复。 元空间的参数 对于元空间大小的控制，JDK提供了两个参数： -XX:MaxMetaspaceSize MaxMetaspaceSize参数控制了元空间的最大可用大小，注意这指的是committed大小。 -XX:CompressedClassSpaceSize CompressedClassSpaceSize参数控制了元空间中_Compressed Class Space_的虚拟空间大小。 元空间与GC 正如上文所说，只有当类加载器被卸载时，GC才会回收，一般来讲，对于元空间的GC在以下两种情况都会被触发： JVM内部维护一个阈值，分配元空间时，元空间大小超过这个阈值，GC就会被触发，收集被卸载的类加载器及其加载的类，以重用空间。 遇到元空间OOM，一般是由于元空间committed大小达到了MaxMetaspaceSize，或者Compressed Class Space耗尽了。此时GC被触发，来尽可能补救。 ","date":"2022-04-03","objectID":"/posts/jvm_metaspace_improvement/:0:2","tags":["java","metaspace"],"title":"JDK元空间的内存分配体系","uri":"/posts/jvm_metaspace_improvement/"},{"categories":null,"content":"2. 元空间的内存分配器 和glibc malloc等一般通用的分配器一样，元空间的内存分配器也分为了许多层： 第一层：VirtualSpaceList 这一层是直接和操作系统打交道的，也是粒度最粗的一层，就像一个经销商，一次性从操作系统批发大块内存。通过mmap等系统调用向OS按需申请内存，在64位系统上，一般是以2MB作为一个region向OS申请。这些申请下来的region在JVM内部被包装成VirtualSpaceNode形成一个VirtualSpaceList： 每个node会有一个水位线(HWM, High Water Mark)，将committed的内存和uncommitted内存分隔开，这个水位线的作用在于留好提前量，当内存分配达到水位线，就会调用OS接口请求新页，从而避免总是node耗尽了再去请求OS。随着内存分配的进行，当前node内存被使用完，此时，就会创建一个新node，添加到list末尾，旧节点就变为退休(retired)状态。注意，旧节点很有可能会有剩余空间，因为可能剩余的空间不足以满足元空间新的分配请求，比如要求200K，但目前只剩下100K，那这个剩下的100K就会被添加到freelist中，以供后续的分配使用，后面会详细介绍这部分。从node中分配出来的内存称之为MetaChunk，MetaChunk的大小分为specialized，small，medium。在64位机器上，其大小分别为1K、4K、64K。与Metachunk 不一样，VirtualSpaceList 和它保存的node都是全局性的，整个JVM进程只会存在一个(未启用指针压缩的情况下)，而一个MetaChunk是被一个classloader持有，如下： 所以：一个node里的chunks，很可能被多个classloder持有。当一个classloader和其相关的类都被卸载了，则其关联的Metaspace就会被释放，被释放的chunk会被添加到一个全局的free list：ChunkManager，如下： 这些空出来的空间就有可能被后续的classloader使用： 中间层：MetaChunk 下面来详细说一下MetaChunk，如前所述，VirtualSpaceList 是全局的，那就必然存在锁的竞争，所以直接向VirtualSpaceList 申请内存，代价是很昂贵的，所以使用了MetaChunk这个中间层来避免锁竞争。而且，MetaChunk一般要比classloader实际所需的内存还要大一点，这也是为了满足classloader后续可能的类加载需求，避免频繁请求VirtualSpaceList 。 那么，到底给多大的MetaChunk给classloader合适呢，实际上，这全靠猜： 一般而言，正常的classloader，给的是4K大小的chunk，如果classloader请求分配器次数超过4次，分配器就会给到64K大小。 bootstrap classloader比较特殊，我们知道，它加载的类是很多的，所以，所以分配器很大方地给4M给它，这个大小可以通过InitialBootClassLoaderMetaspaceSize参数来控制。 对于反射用到的classloader(jdk.internal.reflect.DelegatingClassLoader)和匿名类的classloader，一般会给1K，因为我们知道，这些classloader都只会加载一次类，给太多也是浪费。 给classloader比实际所需更多的内存，是基于这样的假设：classloader后续很可能还会需要内存来进行类加载。但是完全存在这样的可能：刚给完内存，classloader就再也不加载类了。 第三层：Metablock MetaChunk还可以继续划分为Metablock： Metablock才是真正交给classloader的存储单元，一般一个Metablock 存放一个InstanceKlass实例，注意到当前这个Chunk的Unused部分，如果持有这个Chunk的classloader不再加载类了，那Unused部分就是被浪费掉了。上图还有个Deallocated block部分，这指的是在极少数的情况下，元空间会先于类卸载而被释放，比如： 类重定义了，旧的元数据就没用了 或者类加载中出现错误，为该类分配好的元数据就放在那无人问津 这样的情况下，对应的Metablock的状态就是_deallocated，并且_会被添加到 free-block-dictionary 中， ","date":"2022-04-03","objectID":"/posts/jvm_metaspace_improvement/:0:3","tags":["java","metaspace"],"title":"JDK元空间的内存分配体系","uri":"/posts/jvm_metaspace_improvement/"},{"categories":null,"content":"3. ClassloaderData 和 ClassLoaderMetaspace classloader在JVM内部表示为ClassloaderData，ClassloaderData内部持有对ClassLoaderMetaspace的引用，而ClassLoaderMetaspace就保存了这个classloader在使用中的所有MetaChunk。当这个classloader被卸载，对应的ClassloaderData 和 ClassLoaderMetaspace也会一并被删除，于是，这个classloader在使用中的所有MetaChunk会被放入到元空间的free list中去。而是否会被进一步还给操作系统，取决于一定的条件，见下文。 ","date":"2022-04-03","objectID":"/posts/jvm_metaspace_improvement/:0:4","tags":["java","metaspace"],"title":"JDK元空间的内存分配体系","uri":"/posts/jvm_metaspace_improvement/"},{"categories":null,"content":"4. 匿名类 前面我们说，元空间的内存被相应的classloader持有，其实是有一点不准确的，对于匿名类来说，情况要复杂一些： 当一个classloader加载一个匿名类时，会为匿名类生成一份独立的ClassloaderData，而并不是依附于宿主类，所以，匿名类及其元数据就有可能先于宿主类被回收掉。也就是说，对于一个正常的类而言，一个classloader只有一份ClassLoaderData ，而对于匿名类而言，会有一个二级的ClassLoaderData ，如下： 这样分离设计的目的之一，就是避免无谓地延长对lamda和Method Handle元空间分配的生命周期。 回到上面的问题，内存何时还给操作系统呢？答案就是：当VirtualSpaceListNode 里的所有chunk全都是空闲的，并且VirtualSpaceListNode 自身也被从VirtualSpaceList中移除时，这些空闲的chunk就会从free list中移除，node对应的内存就会还给操作系统，此时node的状态称为purged。而要达成上述的条件，就要求所有的chunk，它们对应的classloader都被卸载。这样的可能性到底有多高呢？我们可以计算一下：一个node的大小是2MB，chunk的大小从1K到64K大小不等，正常来讲，一个node会有150至200个chunk，如果这些chunk都被一个classloader持有，那只要卸载这个classloader就能回收内存给操作系统。但如果这些chunk各自被不同生命周期的classloader持有，那这个node就无法被释放，而这种情况在我们加载内部类或者使用反射时是很常见的。还需要注意一点，压缩类空间(Compressed Class Space)是永远不会还给操作系统的。 ","date":"2022-04-03","objectID":"/posts/jvm_metaspace_improvement/:0:5","tags":["java","metaspace"],"title":"JDK元空间的内存分配体系","uri":"/posts/jvm_metaspace_improvement/"},{"categories":null,"content":"5. 压缩类空间(Compressed Class Space) 压缩类空间介绍 压缩类空间其实和压缩指针有关系，压缩指针指的是在64位机器上，使用32位的指针来引用对象。这样做的好处有： 节省空间 能与某些平台上的寄存器更好地协作 关于压缩指针的详细介绍可以看 JVM的压缩指针。 压缩类空间的启用由UseCompressedClassPointers参数控制，默认是开启的。其原理就是32的压缩指针结合基地址，就能得到64位地址。每个java对象，在其头部都会有一个指针指向其对应的Klass实例： 当启用压缩指针时，那这个指针就是32位的，为了找到64位地址的Klass实例，就需要一个公共的基地址： 正是因为这个基地址，对Klass实例的存放提出了内存地址限制：Klass实例的地址必须在4G(未偏移模式)或者32G(偏移模式)内，这样才能用一个32位的偏移量结合一个基地址来取址。这样就要求元空间中存储Klass实例的部分必须是一个连续空间。当我们使用mmap或者malloc等系统调用来申请内存，是无法保证每次申请的地址都在上述要求范围内的。比如，一次mmap调用返回0x0000000700000000，另一次mmap调用返回0x0000000f00000000。于是，我们将元空间分为两部分： 一是储存Klass实例的部分，这就是压缩类空间，称为class part，这部分的内存都是连续的，并且需要提前申请好，且不可扩展。 二就是除了Klass实例之外的其他元数据，称为non-class part，这部分因为没有采用32位偏移+基地址寻址的模式，而是直接采用64位地址寻址，所以就不要求内存连续。 所以，如果不开启压缩类空间，那么元空间内存布局是这样的： 如果开启了，则是这样的： 这样来讲，其实压缩类空间有点名不副实，压缩的并不是Klass实例，而是指向这些实例的指针。压缩类空间的大小由XX:CompressedClassSpaceSize参数控制，默认大小为1G。除此之外，HotSpot还人为规定了压缩类空间的最大大小为3G。 要注意，这里说的都是虚拟地址空间，并不是实际占用内存大小。因为现代操作系统分配内存是按需分配的，让进程以为它拥有了所有内存。 一般来讲，Klass实例大小平均为1K，所有默认1G的压缩类空间，大概能存放100W个Klass实例，这就是JVM能加载的类的个数限制。CompressedClassPointers 只有在CompressedOops 参数启用才会生效，而CompressedOops在Java堆大小大于32G时是自动失效的。 压缩类空间实现 现在，我们回到内存分配器，它是如何支持压缩类空间的呢？如果启用了压缩类空间，那么VirtualSpaceList和ChunkManager这样的全局数据结构就会有两份了，一份管理class part，另一份管理non-class part： 这样，正如我们之前所述，non-class part的内存是连续的，提前申请好的，所以它对应的VirtualSpaceList就退化成了只有一个巨大node的list。而储存其他元数据的class part就是有多个node的VirtualSpaceList。 ","date":"2022-04-03","objectID":"/posts/jvm_metaspace_improvement/:0:6","tags":["java","metaspace"],"title":"JDK元空间的内存分配体系","uri":"/posts/jvm_metaspace_improvement/"},{"categories":null,"content":"6. 元空间大小 元空间大小控制参数 控制元空间大小的关键参数有两个：MaxMetaspaceSize和CompressedClassSpaceSize。MaxMetaspaceSize控制的是元空间内存占用最大大小(这里是实实在在占用的物理内存)，默认是不限制的，意味着如果可能，元空间会用尽所有能用的内存。CompressedClassSpaceSize控制的是压缩类空间的大小(这里是虚拟内存大小)，必须在JVM启动前指定，启动后不能扩展，默认为1G。这两个参数的关系如下图所示： 红色的部分代表元空间占用内存大小，包括了class part和non-class part。如果超过MaxMetaspaceSize，就会导致OutOfMemoryError(“Metaspace”)，如果class part部分的内存占用达到了CompressedClassSpaceSize，就会导致OutOfMemoryError(“Compressed Class Space”)。如果没有启用压缩类空间，那CompressedClassSpaceSize自然就无用了，上面的class part自然不复存在，事情就变得更简单了：元空间大小只由MaxMetaspaceSize限制。 一个类加载到底需要多少元空间？ 一般而言，一个类被加载后，其元数据分布如下： class space： 主要存放Klass实例，紧随其后的是vtable和itable，前者大小取决于类中的方法个数，后者大小取决于实现的接口方法个数，再往后就是oopMap，它一般很小。vtable和itable的大小可以很大，对于一个有3W个方法或者实现了3W个方法的类，其vtable或者itable能达到240K，一般实际编码中，不会有人写出有3W个方法的类，但是在代码自动生成中，倒是有可能出现。 non-class space： 这里存的元数据就比较杂了，其中大头主要有以下几项： 常量池，可变大小 方法的元数据，包括：ConstMethod，ConstMethod中有字节码、局部变量表、异常表、参数信息、签名等 运行时数据，用来给JIT优化使用 注解 对于一个常见的WildFly服务程序，其class space和non-class space占用比如下： 类加载器 类个数 non-class space (avg per class) class space (avg per class) non-class/class all 11503 60381k (5.25k) 9957k (.86k) 6.0 : 1 bootstrap 2819 16720k (5.93k) 1768k (0.62k) 9.5 : 1 app 185 1320k (7.13k) 136k (0.74k) 9.7 : 1 anonymous 869 1013k (1.16k) 475k (0.55k) 2.1 : 1 从上表，可以得出以下结论： 对于从App Classloader和Bootstrap Classloader加载的类，一般每个类平均消耗5-7K的的non-class space和600-900bytes的class space 匿名类占用大小要小得多，但是class space和non-class space的比例显然与其他类也不一样，达到了将近1:2，说明，匿名类虽然小，但是其Klass实例大小也小不到哪儿去，因为肯定不会小于sizeof(Klass)。 从结论1，如果默认CompressedClassSpaceSize为1G，在理想情况下(没有碎片、没有浪费)，压缩类空间最多能放100W-150W个Klass实例。 ","date":"2022-04-03","objectID":"/posts/jvm_metaspace_improvement/:0:7","tags":["java","metaspace"],"title":"JDK元空间的内存分配体系","uri":"/posts/jvm_metaspace_improvement/"},{"categories":null,"content":"7. JDK 16对元空间的重大改进 https://www.yuque.com/boatrainlsz/qlwywg/lc2npw ","date":"2022-04-03","objectID":"/posts/jvm_metaspace_improvement/:0:8","tags":["java","metaspace"],"title":"JDK元空间的内存分配体系","uri":"/posts/jvm_metaspace_improvement/"},{"categories":null,"content":"参考资料 https://zhanjindong.com/2016/03/02/jvm-memory-tunning-notes http://cr.openjdk.java.net/~stuefe/jep387/review/2020-09-03/guide/review-guide.html#11-high-level-overview https://stuefe.de/posts/metaspace/metaspace-architecture/#fnref:1 http://xmlandmore.blogspot.com/2014/08/jdk-8-usecompressedclasspointers-vs.html https://www.oracle.com/webfolder/technetwork/tutorials/mooc/JVM_Troubleshooting/week1/lesson1.pdf https://openjdk.java.net/jeps/387 https://blogs.sap.com/2021/07/16/jep-387-elastic-metaspace-a-new-classroom-for-the-java-virtual-machine/ ","date":"2022-04-03","objectID":"/posts/jvm_metaspace_improvement/:0:9","tags":["java","metaspace"],"title":"JDK元空间的内存分配体系","uri":"/posts/jvm_metaspace_improvement/"},{"categories":null,"content":"本文是对此文章的学习与翻译。 ","date":"2022-04-02","objectID":"/posts/go/:0:0","tags":["go","register"],"title":"基于寄存器调用惯例的Go语言接口调用机制","uri":"/posts/go/"},{"categories":null,"content":"摘要 其实这个机制和Java以及C++的接口调用机制差不多，都是基于itable，不过Java由于虚拟机规范中没有对方法调用惯例做出明确的规定，所以对Java而言，方法调用惯例是基于寄存器还是栈，完全取决于JVM的具体实现，可参考此回答。 ","date":"2022-04-02","objectID":"/posts/go/:0:1","tags":["go","register"],"title":"基于寄存器调用惯例的Go语言接口调用机制","uri":"/posts/go/"},{"categories":null,"content":"Go版本说明 网上的很多博客对于Go语言的方法调用，尤其是接口方法调用的描述已经过时了。因为从1.17版本开始，在AMD64架构上的方法调用就变为了基于寄存器： Go 1.17 implements a new way of passing function arguments and results using registers instead of the stack. Benchmarks for a representative set of Go packages and programs show performance improvements of about 5%, and a typical reduction in binary size of about 2%. This is currently enabled for Linux, macOS, and Windows on the 64-bit x86 architecture (the linux/amd64, darwin/amd64, and windows/amd64 ports). 1.18版本更进一步，将基于寄存器的方法调用惯例扩展到了其他平台： Go 1.17 implemented a new way of passing function arguments and results using registers instead of the stack on 64-bit x86 architecture on selected operating systems. Go 1.18 expands the supported platforms to include 64-bit ARM (GOARCH=arm64), big- and little-endian 64-bit PowerPC (GOARCH=ppc64, ppc64le), as well as 64-bit x86 architecture (GOARCH=amd64) on all operating systems. On 64-bit ARM and 64-bit PowerPC systems, benchmarking shows typical performance improvements of 10% or more. 本篇文章基于最新的Go 1.18，架构为AMD64。 ","date":"2022-04-02","objectID":"/posts/go/:0:2","tags":["go","register"],"title":"基于寄存器调用惯例的Go语言接口调用机制","uri":"/posts/go/"},{"categories":null,"content":"样例代码 本篇文章用冒泡排序算法中的内层循环来讲解： func bubbleUp(x sort.Interface) { n := x.Len() for i := 1; i \u003c n; i++ { if x.Less(i, i-1) { x.Swap(i, i-1) } } } 这里的sort.Interface是Go标准库里的接口，其定义如下： type Interface interface { Len() int Less(i, j int) bool Swap(i, j int) } 只要实现了sort.Interface接口，就可以当作bubbleUp函数的参数x，但最常用的还是slice。 ","date":"2022-04-02","objectID":"/posts/go/:0:3","tags":["go","register"],"title":"基于寄存器调用惯例的Go语言接口调用机制","uri":"/posts/go/"},{"categories":null,"content":"接口的内存布局 接口在Go runtime中的内部表示如下： type iface struct { tab *itab data unsafe.Pointer } 在64位机器上，tab和data都是64bit，共128bit，也就是两个4字，其中itab类型定义如下： type itab struct { inter *interfacetype _type *_type hash uint32 // copy of _type.hash. Used for type switches. _ [4]byte fun [1]uintptr // variable sized. fun[0]==0 means _type does not implement inter. } 这里重点关注fun字段，它是一个可变大小的函数指针数组，这就是分派表 ","date":"2022-04-02","objectID":"/posts/go/:0:4","tags":["go","register"],"title":"基于寄存器调用惯例的Go语言接口调用机制","uri":"/posts/go/"},{"categories":null,"content":"寄存器 目前在AMD64架构上，Go依次使用以下寄存器用作函数调用： RAX, RBX, RCX, RDI, RSI, R8, R9, R10, R11 有时候，一个参数会占用多个寄存器，比如上面说的iface接口，它占用64*2=128bit，那么如果接口值被当作第一个参数传给函数，则其tab字段和data字段将分别占据RAX和RBX寄存器，如果接口值被当作第二个参数传给函数，此时，第一个参数已经占据了RAX，则其tab字段和data字段将分别占据RBX和RCX寄存器，以此类推。顺便提一下，Go语言使用的Plan9汇编语言不使用前缀R来访问这些寄存器(RAX, RBX, RCX, RDI, RSI)，而是直接用AX，BX等名字。 ","date":"2022-04-02","objectID":"/posts/go/:0:5","tags":["go","register"],"title":"基于寄存器调用惯例的Go语言接口调用机制","uri":"/posts/go/"},{"categories":null,"content":"汇编代码 使用如下命令将样例代码反汇编： go tool compile -S bubble.go 关于Go语言的汇编入门，可以参考这篇文章 得到的完整汇编代码见gist。 略去下面这段函数序言： \"\".bubbleUp STEXT size=182 args=0x10 locals=0x38 funcid=0x0 align=0x0 0x0000 00000 (bubble.go:3) TEXT \"\".bubbleUp(SB), ABIInternal, $56-16 0x0000 00000 (bubble.go:3) CMPQ SP, 16(R14) 0x0004 00004 (bubble.go:3) PCDATA $0, $-2 0x0004 00004 (bubble.go:3) JLS 152 0x000a 00010 (bubble.go:3) PCDATA $0, $-1 0x000a 00010 (bubble.go:3) SUBQ $56, SP 0x000e 00014 (bubble.go:3) MOVQ BP, 48(SP) 0x0013 00019 (bubble.go:3) LEAQ 48(SP), BP 略去下面这段GC相关代码： 0x0018 00024 (bubble.go:3) FUNCDATA $0, gclocals·09cf9819fc716118c209c2d2155a3632(SB) 0x0018 00024 (bubble.go:3) FUNCDATA $1, gclocals·69c1753bd5f81501d95132d08af04464(SB) 0x0018 00024 (bubble.go:3) FUNCDATA $5, \"\".bubbleUp.arginfo1(SB) 0x0018 00024 (bubble.go:3) FUNCDATA $6, \"\".bubbleUp.argliveinfo(SB) 重点来分析函数主体代码： 0x0018 00024 (bubble.go:4) MOVQ AX, \"\".x+64(SP) 0x001d 00029 (bubble.go:4) MOVQ BX, \"\".x+72(SP) 0x0022 00034 (bubble.go:4) MOVQ 24(AX), CX 0x0026 00038 (bubble.go:4) MOVQ BX, AX 0x0029 00041 (bubble.go:4) CALL CX 参数暂存 函数开始，如上文所述，接口值将占据AX，BX寄存器：其中AX为MOVQ AX, \"\".x+64(SP)和MOVQ BX, \"\".x+72(SP)将接口值复制到栈上(SP：Stack Pointer)，以便为后续AX，BX寄存器的使用腾出空间。 找到函数调用地址 接下来，准备调用x.Len()，此时，就需要找到要调用的函数，而这个函数的入口地址就存放在24(AX)，其原理是这样的： 如前所述，传递给函数bubbleUp的参数x，其值存放在AX，BX寄存器。 根据iface的内存布局，AX寄存器存放的正是指向itab的指针 24(AX)意思是AX+24，这里24是十进制，表示指针地址+偏移量24bytes itab中24bytes偏移量正是指向itab中的fun字段，也就是接口中的第一个函数的地址被放置在寄存器CX中 而sort.Interface接口的第一个方法正是Len()方法，所以最后，x的Len()方法的地址就存放在CX寄存器中了 调用函数 函数地址找到了，接下来就是调用函数了。因为Len()方法没有参数，所以唯一一个需要传递的参数就是函数的接收者(receiver)，注意到在之前的操作中已经把接口的tab字段和data字段将分别存放到了AX和BX寄存器，data字段正是存放了实际的接口值，也就是函数的接收者，所以接下来使用MOVQ BX, AX将函数的接收者放在AX寄存器中，然后用CALL CX调用函数。 函数返回值 Len()方法返回一个整数n，存放在AX寄存器中，这里将返回值存放到了栈上，因为接下来AX寄存器将用作其他用途： 0x002b 00043 (bubble.go:4) MOVQ AX, \"\".n+24(SP) 开始循环 接下来的代码就是for循环的汇编实现： 0x0030 00048 (bubble.go:4) MOVL $1, CX 0x0035 00053 (bubble.go:5) JMP 69 ---\u003e\\ 0x0037 00055 (bubble.go:5) MOVQ \"\".i+32(SP), DX | 0x003c 00060 (bubble.go:5) LEAQ 1(DX), CX |i++ 0x0040 00064 (bubble.go:5) MOVQ \"\".n+24(SP), AX | 0x0045 00069 (bubble.go:5) CMPQ AX, CX \u003c---/ 0x0048 00072 (bubble.go:5) JLE 142 0x004a 00074 (bubble.go:5) MOVQ CX, \"\".i+32(SP) 0x004f 00079 (bubble.go:6) MOVQ \"\".x+64(SP), DX 0x0054 00084 (bubble.go:6) MOVQ 32(DX), SI 0x0058 00088 (bubble.go:6) LEAQ -1(CX), DI 0x005c 00092 (bubble.go:6) MOVQ DI, \"\"..autotmp_4+40(SP) 0x0061 00097 (bubble.go:6) MOVQ \"\".x+72(SP), AX 0x0066 00102 (bubble.go:6) MOVQ CX, BX 0x0069 00105 (bubble.go:6) MOVQ DI, CX 0x006c 00108 (bubble.go:6) CALL SI 0x006e 00110 (bubble.go:6) TESTB AL, AL 0x0070 00112 (bubble.go:6) JEQ 55 0x0072 00114 (bubble.go:7) MOVQ \"\".x+64(SP), DX 0x0077 00119 (bubble.go:7) MOVQ 40(DX), SI 0x007b 00123 (bubble.go:7) MOVQ \"\".x+72(SP), AX 0x0080 00128 (bubble.go:7) MOVQ \"\".i+32(SP), BX 0x0085 00133 (bubble.go:7) MOVQ \"\"..autotmp_4+40(SP), CX 0x008a 00138 (bubble.go:7) CALL SI 0x008c 00140 (bubble.go:7) JMP 55 0x008e 00142 (bubble.go:10) PCDATA $1, $-1 0x008e 00142 (bubble.go:10) MOVQ 48(SP), BP i++的实现：首先将CX寄存器赋初始值1，然后跳转到第69行CMPQ AX, CX(注意此时AX中的值为n)，也就是比较n和i的大小，并且当i\u003e=n时将跳出循环(JLE 142)。第55行至64行就是i++的实现。 调用x.Less()方法：回想一下，itab中的第一个方法Len()方法的偏移量为24bytes，所以第二个方法，Less()方法的偏移量是32bytes。这里首先将存放于栈上的iface值复制到DX寄存器中，然后再将Less()方法的地址放入SI寄存器，到第105行为止，都是在进行调用x.Less()方法的准备工作。执行到第105行时，此时： Less()方法的接收者x在AX寄存器中 i在BX寄存器中 i-1在CX寄存器中 Less()方法返回值存放在AL寄存器中，0代表false，1代表true，这两行代码判断Less()方法返回值，若为false，则直接跳到55行，继续下个循环，否则继续执行Swap()方法： 0x0072 00114 (bubble.go:7) MOVQ \"\".x+64(SP), DX 0x0077 00119 (bubble.go:7) MOVQ 40(DX), SI 0x007b 00123 (bubble.go:7) MOVQ \"\".x+72(SP), AX 0x0080 00128 (bubble.go:7) MOVQ \"\".i+32(SP), BX 0x0085 00133 (bubble.go:7) MOVQ \"\"..autotmp_4+40(SP), CX 0x008a 00138 (bubble.go:7) CALL SI 紧跟着就是for循环的回边语句： 0x008c 00140 (bubble.go:15) JMP 55 最后就是函数的尾言和返回语句： 0x0093 00147 (bubble.go:10) ADDQ $56, SP 0x0097 00151 (bubble.go:10) RET 0x0098 00152 (bubble.go:10) N ","date":"2022-04-02","objectID":"/posts/go/:0:6","tags":["go","register"],"title":"基于寄存器调用惯例的Go语言接口调用机制","uri":"/posts/go/"},{"categories":null,"content":"go的并发编程示例 package main import ( \"context\" \"fmt\" \"time\" ) func main() { ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second) defer cancel() go handle(ctx, 500*time.Millisecond) select { case \u003c-ctx.Done(): fmt.Println(\"main\", ctx.Err()) } } func handle(ctx context.Context, duration time.Duration) { select { case \u003c-ctx.Done(): fmt.Println(\"handle\", ctx.Err()) case \u003c-time.After(duration): fmt.Println(\"process request with\", duration) } } ","date":"2022-04-01","objectID":"/posts/first_post/:0:0","tags":["go","concurrency"],"title":"go的并发编程","uri":"/posts/first_post/"}]