[{"categories":null,"contents":"整理一下平时常用到的一些脚本 批量删除docker镜像 ###删除mariadb的所有镜像 ###方法1 docker images|grep mariadb | awk \u0026#39;BEGIN{OFS=\u0026#34;:\u0026#34;} {print $1,$2}\u0026#39; | while read line; do docker rmi -f $line done ###方法2：不用read line也可以做到的 docker rmi -f `docker images |grep mariadb |awk \u0026#39;{print $3}\u0026#39;` ","permalink":"https://boatrainlsz.github.io/posts/common_scripts/","tags":["shell","python","powershell"],"title":"平时常用到的一些脚本"},{"categories":null,"contents":"需求 已经在一台机器上安装了trivy，并下载了漏洞数据库。需要在另一台上也使用同版本的数据库，而不是去更新，因为初始化时，trivy都需要强制更新。 实现 在官方issue列表中找到了类似的需求，于是可以这样实现：   在已安装trivy的机器上执行trivy -h命令，找到默认的cache目录，漏洞数据库就存放在这里 ##trivy -h |grep cache --cache-dir value cache directory (default: \u0026#34;/root/.cache/trivy\u0026#34;) [$TRIVY_CACHE_DIR]   将/root/.cache/trivy文件夹复制到另一台机器上的相同路径下   在另一台机器上执行如下命令，即可进行扫描，且不会更新漏洞数据库 trivy --cache-dir /root/.cache/trivy image --skip-update --severity HIGH,CRITICAL $your_image   ","permalink":"https://boatrainlsz.github.io/posts/trivy_share_db/","tags":["trivy","GVE"],"title":"trivy共享漏洞数据库"},{"categories":null,"contents":"","permalink":"https://boatrainlsz.github.io/posts/the-elements-of-computing-systems-ch01/","tags":["计算机系统要素"],"title":"《计算机系统要素》第一章——布尔逻辑"},{"categories":null,"contents":" 这是去年写在语雀上的文章，搬运过来。  前段时间偶然在Twitter看到了SAP工程师的一个分享，这位大佬给OpenJDK提了个JEP，几乎算是重构了JDK元空间的实现，使得JDK的元空间更有弹性，对内存占用更友好，于是花了点时间看了下他的系列文章。简单整理如下： 版本说明 从JDK8以来，元空间的实现方式发生了很大变化，这里以OpenJDK 11为准。 1. 什么是元空间 详见此文，简单来讲，Metaspace是存储类元数据的地方，我们知道在JDK 8之前，类的元数据都是存在堆中的永久代。JDK8后，永久代被废除，元数据都移到了Metaspace里。类的元数据大体可以看做class文件的运行时形式，包括但不限于：  Klass结构：JVM内部对Java Class的表示，其中含有vtable和itable 方法的元数据：method_info的运行时形式，其中有字节码，异常表，常量等 常量池 注解 方法计数器：为了给JIT编译器提供数据 其他数据  元空间何时分配 当一个类被加载完成且它的JVM内部表示已经准备就绪了，它的类加载器就会给它分配对应的元空间： 元空间何时释放 对一个类来说，已分配的元空间被它的类加载器所持有，当且仅当类加载器自身被卸载了，对应的元空间才会被回收掉。也就是说：当且仅当这个类加载器没有被引用且被它加载的类的所有实例也没有被引用时，对应的元空间才会被回收 但是要注意的是，这里说的释放，不是指将内存还给操作系统，被释放的内存，一部分甚至是全部，会以free-list的形式保留，以供后续的类加载时候用。至于到底有多少内存会被保留，取决于元空间的碎片化程度，OpenJDK 11元空间的碎片化问题做了很多修复。 元空间的参数 对于元空间大小的控制，JDK提供了两个参数： -XX:MaxMetaspaceSize MaxMetaspaceSize参数控制了元空间的最大可用大小，注意这指的是committed大小。 -XX:CompressedClassSpaceSize CompressedClassSpaceSize参数控制了元空间中_Compressed Class Space_的虚拟空间大小。 元空间与GC 正如上文所说，只有当类加载器被卸载时，GC才会回收，一般来讲，对于元空间的GC在以下两种情况都会被触发：  JVM内部维护一个阈值，分配元空间时，元空间大小超过这个阈值，GC就会被触发，收集被卸载的类加载器及其加载的类，以重用空间。 遇到元空间OOM，一般是由于元空间committed大小达到了MaxMetaspaceSize，或者Compressed Class Space耗尽了。此时GC被触发，来尽可能补救。  2. 元空间的内存分配器 和glibc malloc等一般通用的分配器一样，元空间的内存分配器也分为了许多层： 第一层：VirtualSpaceList 这一层是直接和操作系统打交道的，也是粒度最粗的一层，就像一个经销商，一次性从操作系统批发大块内存。通过mmap等系统调用向OS按需申请内存，在64位系统上，一般是以2MB作为一个region向OS申请。这些申请下来的region在JVM内部被包装成VirtualSpaceNode形成一个VirtualSpaceList： 每个node会有一个水位线(HWM, High Water Mark)，将committed的内存和uncommitted内存分隔开，这个水位线的作用在于留好提前量，当内存分配达到水位线，就会调用OS接口请求新页，从而避免总是node耗尽了再去请求OS。随着内存分配的进行，当前node内存被使用完，此时，就会创建一个新node，添加到list末尾，旧节点就变为退休(retired)状态。注意，旧节点很有可能会有剩余空间，因为可能剩余的空间不足以满足元空间新的分配请求，比如要求200K，但目前只剩下100K，那这个剩下的100K就会被添加到freelist中，以供后续的分配使用，后面会详细介绍这部分。从node中分配出来的内存称之为MetaChunk，MetaChunk的大小分为specialized，small，medium。在64位机器上，其大小分别为1K、4K、64K。与Metachunk 不一样，VirtualSpaceList 和它保存的node都是全局性的，整个JVM进程只会存在一个(未启用指针压缩的情况下)，而一个MetaChunk是被一个classloader持有，如下： 所以：一个node里的chunks，很可能被多个classloder持有。当一个classloader和其相关的类都被卸载了，则其关联的Metaspace就会被释放，被释放的chunk会被添加到一个全局的free list：ChunkManager，如下： 这些空出来的空间就有可能被后续的classloader使用： 中间层：MetaChunk 下面来详细说一下MetaChunk，如前所述，VirtualSpaceList 是全局的，那就必然存在锁的竞争，所以直接向VirtualSpaceList 申请内存，代价是很昂贵的，所以使用了MetaChunk这个中间层来避免锁竞争。而且，MetaChunk一般要比classloader实际所需的内存还要大一点，这也是为了满足classloader后续可能的类加载需求，避免频繁请求VirtualSpaceList 。 那么，到底给多大的MetaChunk给classloader合适呢，实际上，这全靠猜：  一般而言，正常的classloader，给的是4K大小的chunk，如果classloader请求分配器次数超过4次，分配器就会给到64K大小。 bootstrap classloader比较特殊，我们知道，它加载的类是很多的，所以，所以分配器很大方地给4M给它，这个大小可以通过InitialBootClassLoaderMetaspaceSize参数来控制。 对于反射用到的classloader(jdk.internal.reflect.DelegatingClassLoader)和匿名类的classloader，一般会给1K，因为我们知道，这些classloader都只会加载一次类，给太多也是浪费。  给classloader比实际所需更多的内存，是基于这样的假设：classloader后续很可能还会需要内存来进行类加载。但是完全存在这样的可能：刚给完内存，classloader就再也不加载类了。 第三层：Metablock MetaChunk还可以继续划分为Metablock： Metablock才是真正交给classloader的存储单元，一般一个Metablock 存放一个InstanceKlass实例，注意到当前这个Chunk的Unused部分，如果持有这个Chunk的classloader不再加载类了，那Unused部分就是被浪费掉了。上图还有个Deallocated block部分，这指的是在极少数的情况下，元空间会先于类卸载而被释放，比如：  类重定义了，旧的元数据就没用了 或者类加载中出现错误，为该类分配好的元数据就放在那无人问津  这样的情况下，对应的Metablock的状态就是_deallocated，并且_会被添加到 free-block-dictionary 中， 3. ClassloaderData 和 ClassLoaderMetaspace classloader在JVM内部表示为ClassloaderData，ClassloaderData内部持有对ClassLoaderMetaspace的引用，而ClassLoaderMetaspace就保存了这个classloader在使用中的所有MetaChunk。当这个classloader被卸载，对应的ClassloaderData 和 ClassLoaderMetaspace也会一并被删除，于是，这个classloader在使用中的所有MetaChunk会被放入到元空间的free list中去。而是否会被进一步还给操作系统，取决于一定的条件，见下文。 4. 匿名类 前面我们说，元空间的内存被相应的classloader持有，其实是有一点不准确的，对于匿名类来说，情况要复杂一些： 当一个classloader加载一个匿名类时，会为匿名类生成一份独立的ClassloaderData，而并不是依附于宿主类，所以，匿名类及其元数据就有可能先于宿主类被回收掉。也就是说，对于一个正常的类而言，一个classloader只有一份ClassLoaderData ，而对于匿名类而言，会有一个二级的ClassLoaderData ，如下： 这样分离设计的目的之一，就是避免无谓地延长对lamda和Method Handle元空间分配的生命周期。 回到上面的问题，内存何时还给操作系统呢？答案就是：当VirtualSpaceListNode 里的所有chunk全都是空闲的，并且VirtualSpaceListNode 自身也被从VirtualSpaceList中移除时，这些空闲的chunk就会从free list中移除，node对应的内存就会还给操作系统，此时node的状态称为purged。而要达成上述的条件，就要求所有的chunk，它们对应的classloader都被卸载。这样的可能性到底有多高呢？我们可以计算一下：一个node的大小是2MB，chunk的大小从1K到64K大小不等，正常来讲，一个node会有150至200个chunk，如果这些chunk都被一个classloader持有，那只要卸载这个classloader就能回收内存给操作系统。但如果这些chunk各自被不同生命周期的classloader持有，那这个node就无法被释放，而这种情况在我们加载内部类或者使用反射时是很常见的。还需要注意一点，压缩类空间(Compressed Class Space)是永远不会还给操作系统的。 5. 压缩类空间(Compressed Class Space) 压缩类空间介绍 压缩类空间其实和压缩指针有关系，压缩指针指的是在64位机器上，使用32位的指针来引用对象。这样做的好处有：  节省空间 能与某些平台上的寄存器更好地协作  关于压缩指针的详细介绍可以看JVM的压缩指针。 压缩类空间的启用由UseCompressedClassPointers参数控制，默认是开启的。其原理就是32的压缩指针结合基地址，就能得到64位地址。每个java对象，在其头部都会有一个指针指向其对应的Klass实例： 当启用压缩指针时，那这个指针就是32位的，为了找到64位地址的Klass实例，就需要一个公共的基地址： 正是因为这个基地址，对Klass实例的存放提出了内存地址限制：Klass实例的地址必须在4G(未偏移模式)或者32G(偏移模式)内，这样才能用一个32位的偏移量结合一个基地址来取址。这样就要求元空间中存储Klass实例的部分必须是一个连续空间。当我们使用mmap或者malloc等系统调用来申请内存，是无法保证每次申请的地址都在上述要求范围内的。比如，一次mmap调用返回0x0000000700000000，另一次mmap调用返回0x0000000f00000000。于是，我们将元空间分为两部分：  一是储存Klass实例的部分，这就是压缩类空间，称为class part，这部分的内存都是连续的，并且需要提前申请好，且不可扩展。 二就是除了Klass实例之外的其他元数据，称为non-class part，这部分因为没有采用32位偏移+基地址寻址的模式，而是直接采用64位地址寻址，所以就不要求内存连续。  所以，如果不开启压缩类空间，那么元空间内存布局是这样的： 如果开启了，则是这样的： 这样来讲，其实压缩类空间有点名不副实，压缩的并不是Klass实例，而是指向这些实例的指针。压缩类空间的大小由XX:CompressedClassSpaceSize参数控制，默认大小为1G。除此之外，HotSpot还人为规定了压缩类空间的最大大小为3G。 要注意，这里说的都是虚拟地址空间，并不是实际占用内存大小。因为现代操作系统分配内存是按需分配的，让进程以为它拥有了所有内存。 一般来讲，Klass实例大小平均为1K，所有默认1G的压缩类空间，大概能存放100W个Klass实例，这就是JVM能加载的类的个数限制。CompressedClassPointers 只有在CompressedOops 参数启用才会生效，而CompressedOops在Java堆大小大于32G时是自动失效的。 压缩类空间实现 现在，我们回到内存分配器，它是如何支持压缩类空间的呢？如果启用了压缩类空间，那么VirtualSpaceList和ChunkManager这样的全局数据结构就会有两份了，一份管理class part，另一份管理non-class part： 这样，正如我们之前所述，non-class part的内存是连续的，提前申请好的，所以它对应的VirtualSpaceList就退化成了只有一个巨大node的list。而储存其他元数据的class part就是有多个node的VirtualSpaceList。 6. 元空间大小 元空间大小控制参数 控制元空间大小的关键参数有两个：MaxMetaspaceSize和CompressedClassSpaceSize。MaxMetaspaceSize控制的是元空间内存占用最大大小(这里是实实在在占用的物理内存)，默认是不限制的，意味着如果可能，元空间会用尽所有能用的内存。CompressedClassSpaceSize控制的是压缩类空间的大小(这里是虚拟内存大小)，必须在JVM启动前指定，启动后不能扩展，默认为1G。这两个参数的关系如下图所示： 红色的部分代表元空间占用内存大小，包括了class part和non-class part。如果超过MaxMetaspaceSize，就会导致OutOfMemoryError(“Metaspace”)，如果class part部分的内存占用达到了CompressedClassSpaceSize，就会导致OutOfMemoryError(“Compressed Class Space”)。如果没有启用压缩类空间，那CompressedClassSpaceSize自然就无用了，上面的class part自然不复存在，事情就变得更简单了：元空间大小只由MaxMetaspaceSize限制。 一个类加载到底需要多少元空间？ 一般而言，一个类被加载后，其元数据分布如下： class space： 主要存放Klass实例，紧随其后的是vtable和itable，前者大小取决于类中的方法个数，后者大小取决于实现的接口方法个数，再往后就是oopMap，它一般很小。vtable和itable的大小可以很大，对于一个有3W个方法或者实现了3W个方法的类，其vtable或者itable能达到240K，一般实际编码中，不会有人写出有3W个方法的类，但是在代码自动生成中，倒是有可能出现。 non-class space： 这里存的元数据就比较杂了，其中大头主要有以下几项：  常量池，可变大小 方法的元数据，包括：ConstMethod，ConstMethod中有字节码、局部变量表、异常表、参数信息、签名等 运行时数据，用来给JIT优化使用 注解  对于一个常见的WildFly服务程序，其class space和non-class space占用比如下：    类加载器 类个数 non-class space (avg per class) class space (avg per class) non-class/class     all 11503 60381k (5.25k) 9957k (.86k) 6.0 : 1   bootstrap 2819 16720k (5.93k) 1768k (0.62k) 9.5 : 1   app 185 1320k (7.13k) 136k (0.74k) 9.7 : 1   anonymous 869 1013k (1.16k) 475k (0.55k) 2.1 : 1    从上表，可以得出以下结论：  对于从App Classloader和Bootstrap Classloader加载的类，一般每个类平均消耗5-7K的的non-class space和600-900bytes的class space 匿名类占用大小要小得多，但是class space和non-class space的比例显然与其他类也不一样，达到了将近1:2，说明，匿名类虽然小，但是其Klass实例大小也小不到哪儿去，因为肯定不会小于sizeof(Klass)。 从结论1，如果默认CompressedClassSpaceSize为1G，在理想情况下(没有碎片、没有浪费)，压缩类空间最多能放100W-150W个Klass实例。  7. JDK 16对元空间的重大改进 https://www.yuque.com/boatrainlsz/qlwywg/lc2npw 参考资料 https://zhanjindong.com/2016/03/02/jvm-memory-tunning-notes http://cr.openjdk.java.net/~stuefe/jep387/review/2020-09-03/guide/review-guide.html#11-high-level-overview https://stuefe.de/posts/metaspace/metaspace-architecture/#fnref:1 http://xmlandmore.blogspot.com/2014/08/jdk-8-usecompressedclasspointers-vs.html https://www.oracle.com/webfolder/technetwork/tutorials/mooc/JVM_Troubleshooting/week1/lesson1.pdf https://openjdk.java.net/jeps/387 https://blogs.sap.com/2021/07/16/jep-387-elastic-metaspace-a-new-classroom-for-the-java-virtual-machine/ ","permalink":"https://boatrainlsz.github.io/posts/jvm_metaspace_improvement/","tags":["java","metaspace"],"title":"JDK元空间的内存分配体系"},{"categories":null,"contents":"本文是对此文章的学习与翻译。 摘要 其实这个机制和Java以及C++的接口调用机制差不多，都是基于itable，不过Java由于虚拟机规范中没有对方法调用惯例做出明确的规定，所以对Java而言，方法调用惯例是基于寄存器还是栈，完全取决于JVM的具体实现，可参考此回答。 Go版本说明 网上的很多博客对于Go语言的方法调用，尤其是接口方法调用的描述已经过时了。因为从1.17版本开始，在AMD64架构上的方法调用就变为了基于寄存器：  Go 1.17 implements a new way of passing function arguments and results using registers instead of the stack. Benchmarks for a representative set of Go packages and programs show performance improvements of about 5%, and a typical reduction in binary size of about 2%. This is currently enabled for Linux, macOS, and Windows on the 64-bit x86 architecture (the linux/amd64, darwin/amd64, and windows/amd64 ports).  1.18版本更进一步，将基于寄存器的方法调用惯例扩展到了其他平台：  Go 1.17 implemented a new way of passing function arguments and results using registers instead of the stack on 64-bit x86 architecture on selected operating systems. Go 1.18 expands the supported platforms to include 64-bit ARM (GOARCH=arm64), big- and little-endian 64-bit PowerPC (GOARCH=ppc64, ppc64le), as well as 64-bit x86 architecture (GOARCH=amd64) on all operating systems. On 64-bit ARM and 64-bit PowerPC systems, benchmarking shows typical performance improvements of 10% or more.  本篇文章基于最新的Go 1.18，架构为AMD64。 样例代码 本篇文章用冒泡排序算法中的内层循环来讲解： func bubbleUp(x sort.Interface) { n := x.Len() for i := 1; i \u0026lt; n; i++ { if x.Less(i, i-1) { x.Swap(i, i-1) } } } 这里的sort.Interface是Go标准库里的接口，其定义如下： type Interface interface { Len() int Less(i, j int) bool Swap(i, j int) } 只要实现了sort.Interface接口，就可以当作bubbleUp函数的参数x，但最常用的还是slice。 接口的内存布局 接口在Go runtime中的内部表示如下： type iface struct { tab *itab data unsafe.Pointer } 在64位机器上，tab和data都是64bit，共128bit，也就是两个4字，其中itab类型定义如下： type itab struct { inter *interfacetype _type *_type hash uint32 // copy of _type.hash. Used for type switches.  _ [4]byte fun [1]uintptr // variable sized. fun[0]==0 means _type does not implement inter. } 这里重点关注fun字段，它是一个可变大小的函数指针数组，这就是分派表 寄存器 目前在AMD64架构上，Go依次使用以下寄存器用作函数调用：  RAX, RBX, RCX, RDI, RSI, R8, R9, R10, R11  有时候，一个参数会占用多个寄存器，比如上面说的iface接口，它占用64*2=128bit，那么如果接口值被当作第一个参数传给函数，则其tab字段和data字段将分别占据RAX和RBX寄存器，如果接口值被当作第二个参数传给函数，此时，第一个参数已经占据了RAX，则其tab字段和data字段将分别占据RBX和RCX寄存器，以此类推。顺便提一下，Go语言使用的Plan9汇编语言不使用前缀R来访问这些寄存器(RAX, RBX, RCX, RDI, RSI)，而是直接用AX，BX等名字。 汇编代码 使用如下命令将样例代码反汇编： go tool compile -S bubble.go  关于Go语言的汇编入门，可以参考这篇文章  得到的完整汇编代码见gist。 略去下面这段函数序言： \u0026#34;\u0026#34;.bubbleUp STEXT size=182 args=0x10 locals=0x38 funcid=0x0 align=0x0 0x0000 00000 (bubble.go:3) TEXT \u0026#34;\u0026#34;.bubbleUp(SB), ABIInternal, $56-16 0x0000 00000 (bubble.go:3) CMPQ SP, 16(R14) 0x0004 00004 (bubble.go:3) PCDATA $0, $-2 0x0004 00004 (bubble.go:3) JLS 152 0x000a 00010 (bubble.go:3) PCDATA $0, $-1 0x000a 00010 (bubble.go:3) SUBQ $56, SP 0x000e 00014 (bubble.go:3) MOVQ BP, 48(SP) 0x0013 00019 (bubble.go:3) LEAQ 48(SP), BP 略去下面这段GC相关代码： 0x0018 00024 (bubble.go:3) FUNCDATA $0, gclocals·09cf9819fc716118c209c2d2155a3632(SB) 0x0018 00024 (bubble.go:3) FUNCDATA $1, gclocals·69c1753bd5f81501d95132d08af04464(SB) 0x0018 00024 (bubble.go:3) FUNCDATA $5, \u0026#34;\u0026#34;.bubbleUp.arginfo1(SB) 0x0018 00024 (bubble.go:3) FUNCDATA $6, \u0026#34;\u0026#34;.bubbleUp.argliveinfo(SB) 重点来分析函数主体代码： 0x0018 00024 (bubble.go:4) MOVQ AX, \u0026#34;\u0026#34;.x+64(SP) 0x001d 00029 (bubble.go:4) MOVQ BX, \u0026#34;\u0026#34;.x+72(SP) 0x0022 00034 (bubble.go:4) MOVQ 24(AX), CX 0x0026 00038 (bubble.go:4) MOVQ BX, AX 0x0029 00041 (bubble.go:4) CALL CX 参数暂存 函数开始，如上文所述，接口值将占据AX，BX寄存器：其中AX为MOVQ AX, \u0026quot;\u0026quot;.x+64(SP)和MOVQ BX, \u0026quot;\u0026quot;.x+72(SP)将接口值复制到栈上(SP：Stack Pointer)，以便为后续AX，BX寄存器的使用腾出空间。 找到函数调用地址 接下来，准备调用x.Len()，此时，就需要找到要调用的函数，而这个函数的入口地址就存放在24(AX)，其原理是这样的：  如前所述，传递给函数bubbleUp的参数x，其值存放在AX，BX寄存器。 根据iface的内存布局，AX寄存器存放的正是指向itab的指针 24(AX)意思是AX+24，这里24是十进制，表示指针地址+偏移量24bytes itab中24bytes偏移量正是指向itab中的fun字段，也就是接口中的第一个函数的地址被放置在寄存器CX中 而sort.Interface接口的第一个方法正是Len()方法，所以最后，x的Len()方法的地址就存放在CX寄存器中了  调用函数 函数地址找到了，接下来就是调用函数了。因为Len()方法没有参数，所以唯一一个需要传递的参数就是函数的接收者(receiver)，注意到在之前的操作中已经把接口的tab字段和data字段将分别存放到了AX和BX寄存器，data字段正是存放了实际的接口值，也就是函数的接收者，所以接下来使用MOVQ BX, AX将函数的接收者放在AX寄存器中，然后用CALL CX调用函数。 函数返回值 Len()方法返回一个整数n，存放在AX寄存器中，这里将返回值存放到了栈上，因为接下来AX寄存器将用作其他用途： 0x002b 00043 (bubble.go:4) MOVQ AX, \u0026#34;\u0026#34;.n+24(SP) 开始循环 接下来的代码就是for循环的汇编实现： 0x0030 00048 (bubble.go:4) MOVL $1, CX 0x0035 00053 (bubble.go:5) JMP 69 ---\u0026gt;\\ 0x0037 00055 (bubble.go:5) MOVQ \u0026#34;\u0026#34;.i+32(SP), DX | 0x003c 00060 (bubble.go:5) LEAQ 1(DX), CX |i++ 0x0040 00064 (bubble.go:5) MOVQ \u0026#34;\u0026#34;.n+24(SP), AX | 0x0045 00069 (bubble.go:5) CMPQ AX, CX \u0026lt;---/ 0x0048 00072 (bubble.go:5) JLE 142 0x004a 00074 (bubble.go:5) MOVQ CX, \u0026#34;\u0026#34;.i+32(SP) 0x004f 00079 (bubble.go:6) MOVQ \u0026#34;\u0026#34;.x+64(SP), DX 0x0054 00084 (bubble.go:6) MOVQ 32(DX), SI 0x0058 00088 (bubble.go:6) LEAQ -1(CX), DI 0x005c 00092 (bubble.go:6) MOVQ DI, \u0026#34;\u0026#34;..autotmp_4+40(SP) 0x0061 00097 (bubble.go:6) MOVQ \u0026#34;\u0026#34;.x+72(SP), AX 0x0066 00102 (bubble.go:6) MOVQ CX, BX 0x0069 00105 (bubble.go:6) MOVQ DI, CX 0x006c 00108 (bubble.go:6) CALL SI 0x006e 00110 (bubble.go:6) TESTB AL, AL 0x0070 00112 (bubble.go:6) JEQ 55 0x0072 00114 (bubble.go:7) MOVQ \u0026#34;\u0026#34;.x+64(SP), DX 0x0077 00119 (bubble.go:7) MOVQ 40(DX), SI 0x007b 00123 (bubble.go:7) MOVQ \u0026#34;\u0026#34;.x+72(SP), AX 0x0080 00128 (bubble.go:7) MOVQ \u0026#34;\u0026#34;.i+32(SP), BX 0x0085 00133 (bubble.go:7) MOVQ \u0026#34;\u0026#34;..autotmp_4+40(SP), CX 0x008a 00138 (bubble.go:7) CALL SI 0x008c 00140 (bubble.go:7) JMP 55 0x008e 00142 (bubble.go:10) PCDATA $1, $-1 0x008e 00142 (bubble.go:10) MOVQ 48(SP), BP i++的实现：首先将CX寄存器赋初始值1，然后跳转到第69行CMPQ AX, CX(注意此时AX中的值为n)，也就是比较n和i的大小，并且当i\u0026gt;=n时将跳出循环(JLE 142)。第55行至64行就是i++的实现。 调用x.Less()方法：回想一下，itab中的第一个方法Len()方法的偏移量为24bytes，所以第二个方法，Less()方法的偏移量是32bytes。这里首先将存放于栈上的iface值复制到DX寄存器中，然后再将Less()方法的地址放入SI寄存器，到第105行为止，都是在进行调用x.Less()方法的准备工作。执行到第105行时，此时：  Less()方法的接收者x在AX寄存器中 i在BX寄存器中 i-1在CX寄存器中  Less()方法返回值存放在AL寄存器中，0代表false，1代表true，这两行代码判断Less()方法返回值，若为false，则直接跳到55行，继续下个循环，否则继续执行Swap()方法： 0x0072 00114 (bubble.go:7) MOVQ \u0026#34;\u0026#34;.x+64(SP), DX 0x0077 00119 (bubble.go:7) MOVQ 40(DX), SI 0x007b 00123 (bubble.go:7) MOVQ \u0026#34;\u0026#34;.x+72(SP), AX 0x0080 00128 (bubble.go:7) MOVQ \u0026#34;\u0026#34;.i+32(SP), BX 0x0085 00133 (bubble.go:7) MOVQ \u0026#34;\u0026#34;..autotmp_4+40(SP), CX 0x008a 00138 (bubble.go:7) CALL SI 紧跟着就是for循环的回边语句： 0x008c 00140 (bubble.go:15) JMP 55 最后就是函数的尾言和返回语句： 0x0093 00147 (bubble.go:10) ADDQ $56, SP 0x0097 00151 (bubble.go:10) RET 0x0098 00152 (bubble.go:10) N ","permalink":"https://boatrainlsz.github.io/posts/go/","tags":["go","register"],"title":"基于寄存器调用惯例的Go语言接口调用机制"},{"categories":null,"contents":"go的并发编程示例 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second) defer cancel() go handle(ctx, 500*time.Millisecond) select { case \u0026lt;-ctx.Done(): fmt.Println(\u0026#34;main\u0026#34;, ctx.Err()) } } func handle(ctx context.Context, duration time.Duration) { select { case \u0026lt;-ctx.Done(): fmt.Println(\u0026#34;handle\u0026#34;, ctx.Err()) case \u0026lt;-time.After(duration): fmt.Println(\u0026#34;process request with\u0026#34;, duration) } } ","permalink":"https://boatrainlsz.github.io/posts/first_post/","tags":["go","concurrency"],"title":"go的并发编程"},{"categories":null,"contents":"","permalink":"https://boatrainlsz.github.io/search/","tags":null,"title":"Search"}]